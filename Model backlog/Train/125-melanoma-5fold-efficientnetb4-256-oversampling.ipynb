{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 20.2 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet efficientnet\n",
    "# !pip install --quiet image-classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "import warnings, json, re, glob, math\n",
    "# from scripts_step_lr_schedulers import *\n",
    "from melanoma_utility_scripts import *\n",
    "from kaggle_datasets import KaggleDatasets\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow.keras.layers as L\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras import optimizers, layers, metrics, losses, Model\n",
    "import tensorflow_addons as tfa\n",
    "import efficientnet.tfkeras as efn\n",
    "# from classification_models.tfkeras import Classifiers\n",
    "\n",
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## TPU configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS: 8\n"
     ]
    }
   ],
   "source": [
    "strategy, tpu = set_up_strategy()\n",
    "REPLICAS = strategy.num_replicas_in_sync\n",
    "print(f'REPLICAS: {REPLICAS}')\n",
    "AUTO = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HEIGHT': 256,\n",
       " 'WIDTH': 256,\n",
       " 'CHANNELS': 3,\n",
       " 'BATCH_SIZE': 32,\n",
       " 'EPOCHS': 12,\n",
       " 'LEARNING_RATE': 0.0003,\n",
       " 'ES_PATIENCE': 5,\n",
       " 'N_FOLDS': 5,\n",
       " 'N_USED_FOLDS': 5,\n",
       " 'TTA_STEPS': 25,\n",
       " 'BASE_MODEL': 'EfficientNetB4',\n",
       " 'BASE_MODEL_WEIGHTS': 'imagenet',\n",
       " 'DATASET_PATH': 'melanoma-256x256'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "  \"HEIGHT\": 256,\n",
    "  \"WIDTH\": 256,\n",
    "  \"CHANNELS\": 3,\n",
    "  \"BATCH_SIZE\": 32,\n",
    "  \"EPOCHS\": 12,\n",
    "  \"LEARNING_RATE\": 3e-4,\n",
    "  \"ES_PATIENCE\": 5,\n",
    "  \"N_FOLDS\": 5,\n",
    "  \"N_USED_FOLDS\": 5,\n",
    "  \"TTA_STEPS\": 25,\n",
    "  \"BASE_MODEL\": 'EfficientNetB4',\n",
    "  \"BASE_MODEL_WEIGHTS\": 'imagenet',\n",
    "  \"DATASET_PATH\": 'melanoma-256x256'\n",
    "}\n",
    "\n",
    "with open('config.json', 'w') as json_file:\n",
    "    json.dump(json.loads(json.dumps(config)), json_file)\n",
    "    \n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 33126\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
       "\n",
       "  diagnosis benign_malignant  target  \n",
       "0   unknown           benign       0  \n",
       "1   unknown           benign       0  \n",
       "2     nevus           benign       0  \n",
       "3   unknown           benign       0  \n",
       "4   unknown           benign       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test samples: 10982\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>IP_3579794</td>\n",
       "      <td>male</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>IP_7782715</td>\n",
       "      <td>male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>IP_7960270</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>IP_6375035</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>torso</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>IP_0589375</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>lower extremity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge\n",
       "0  ISIC_0052060  IP_3579794    male        70.0                           NaN\n",
       "1  ISIC_0052349  IP_7782715    male        40.0               lower extremity\n",
       "2  ISIC_0058510  IP_7960270  female        55.0                         torso\n",
       "3  ISIC_0073313  IP_6375035  female        50.0                         torso\n",
       "4  ISIC_0073502  IP_0589375  female        45.0               lower extremity"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "database_base_path = '/kaggle/input/siim-isic-melanoma-classification/'\n",
    "train = pd.read_csv(database_base_path + 'train.csv')\n",
    "test = pd.read_csv(database_base_path + 'test.csv')\n",
    "\n",
    "print('Train samples: %d' % len(train))\n",
    "display(train.head())\n",
    "print(f'Test samples: {len(test)}')\n",
    "display(test.head())\n",
    "\n",
    "GCS_PATH = KaggleDatasets().get_gcs_path(f\"melanoma-{config['HEIGHT']}x{config['WIDTH']}\")\n",
    "GCS_2019_PATH = KaggleDatasets().get_gcs_path(f\"isic2019-{config['HEIGHT']}x{config['WIDTH']}\")\n",
    "GCS_MALIGNANT_PATH = KaggleDatasets().get_gcs_path(f\"malignant-v2-{config['HEIGHT']}x{config['WIDTH']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def data_augment(image):\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_shear = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    if p_shear > .2:\n",
    "        if p_shear > .6:\n",
    "            image = transform_shear(image, config['HEIGHT'], shear=5.)\n",
    "        else:\n",
    "            image = transform_shear(image, config['HEIGHT'], shear=-5.)\n",
    "    \n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, config['HEIGHT'], rotation=45.)\n",
    "        else:\n",
    "            image = transform_rotation(image, config['HEIGHT'], rotation=-45.)\n",
    "\n",
    "    if p_crop > .5:\n",
    "        image = data_augment_crop(image)\n",
    "\n",
    "    if p_rotate > .2:\n",
    "        image = data_augment_rotate(image)\n",
    "        \n",
    "    image = data_augment_spatial(image)\n",
    "    \n",
    "    image = tf.image.random_saturation(image, 0.7, 1.3)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    image = tf.image.random_brightness(image, 0.1)\n",
    "    \n",
    "    if p_cutout > .7:\n",
    "        image = data_augment_cutout(image)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def data_augment_tta(image):\n",
    "    p_rotation = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    \n",
    "    if p_rotation > .2:\n",
    "        if p_rotation > .6:\n",
    "            image = transform_rotation(image, config['HEIGHT'], rotation=45.)\n",
    "        else:\n",
    "            image = transform_rotation(image, config['HEIGHT'], rotation=-45.)\n",
    "\n",
    "    if p_crop > .5:\n",
    "        image = data_augment_crop(image)\n",
    "\n",
    "    if p_rotate > .2:\n",
    "        image = data_augment_rotate(image)\n",
    "        \n",
    "    image = data_augment_spatial(image)\n",
    "    \n",
    "    image = tf.image.random_saturation(image, 0.7, 1.3)\n",
    "    image = tf.image.random_contrast(image, 0.8, 1.2)\n",
    "    image = tf.image.random_brightness(image, 0.1)\n",
    "    \n",
    "    return image\n",
    "\n",
    "\n",
    "def data_augment_spatial(image):\n",
    "    p_spatial = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    if p_spatial > .75:\n",
    "        image = tf.image.transpose(image)\n",
    "\n",
    "    return image\n",
    "\n",
    "def data_augment_rotate(image):\n",
    "    p_rotate = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    if p_rotate > .66:\n",
    "        image = tf.image.rot90(image, k=3) # rotate 270ยบ\n",
    "    elif p_rotate > .33:\n",
    "        image = tf.image.rot90(image, k=2) # rotate 180ยบ\n",
    "    else:\n",
    "        image = tf.image.rot90(image, k=1) # rotate 90ยบ\n",
    "\n",
    "    return image\n",
    "\n",
    "def data_augment_crop(image):\n",
    "    p_crop = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    crop_size = tf.random.uniform([], int(config['HEIGHT']*.7), config['HEIGHT'], dtype=tf.int32)\n",
    "    \n",
    "    if p_crop > .5:\n",
    "        image = tf.image.random_crop(image, size=[crop_size, crop_size, config['CHANNELS']])\n",
    "    else:\n",
    "        if p_crop > .4:\n",
    "            image = tf.image.central_crop(image, central_fraction=.7)\n",
    "        elif p_crop > .2:\n",
    "            image = tf.image.central_crop(image, central_fraction=.8)\n",
    "        else:\n",
    "            image = tf.image.central_crop(image, central_fraction=.9)\n",
    "    \n",
    "    image = tf.image.resize(image, size=[config['HEIGHT'], config['WIDTH']])\n",
    "\n",
    "    return image\n",
    "\n",
    "def data_augment_cutout(image, min_mask_size=(int(config['HEIGHT'] * .1), int(config['HEIGHT'] * .1)), \n",
    "                        max_mask_size=(int(config['HEIGHT'] * .125), int(config['HEIGHT'] * .125))):\n",
    "    p_cutout = tf.random.uniform([], 0, 1.0, dtype=tf.float32)\n",
    "    \n",
    "    if p_cutout > .85: # 10~15 cut outs\n",
    "        n_cutout = tf.random.uniform([], 10, 15, dtype=tf.int32)\n",
    "        image = random_cutout(image, config['HEIGHT'], config['WIDTH'], \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .6: # 5~10 cut outs\n",
    "        n_cutout = tf.random.uniform([], 5, 10, dtype=tf.int32)\n",
    "        image = random_cutout(image, config['HEIGHT'], config['WIDTH'], \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    elif p_cutout > .25: # 2~5 cut outs\n",
    "        n_cutout = tf.random.uniform([], 2, 5, dtype=tf.int32)\n",
    "        image = random_cutout(image, config['HEIGHT'], config['WIDTH'], \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=n_cutout)\n",
    "    else: # 1 cut out\n",
    "        image = random_cutout(image, config['HEIGHT'], config['WIDTH'], \n",
    "                              min_mask_size=min_mask_size, max_mask_size=max_mask_size, k=1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def read_labeled_tfrecord(example):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "        'patient_id'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'sex'                          : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'age_approx'                   : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'anatom_site_general_challenge': tf.io.FixedLenFeature([], tf.int64),\n",
    "        'diagnosis'                    : tf.io.FixedLenFeature([], tf.int64),\n",
    "        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n",
    "    }           \n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['target']\n",
    "\n",
    "def read_unlabeled_tfrecord(example, return_image_name):\n",
    "    tfrec_format = {\n",
    "        'image'                        : tf.io.FixedLenFeature([], tf.string),\n",
    "        'image_name'                   : tf.io.FixedLenFeature([], tf.string),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrec_format)\n",
    "    return example['image'], example['image_name'] if return_image_name else 0\n",
    " \n",
    "def prepare_image(img, augment=None, dim=256):    \n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "    \n",
    "    if augment:\n",
    "        img = augment(img)\n",
    "                      \n",
    "    img = tf.reshape(img, [dim, dim, 3])\n",
    "            \n",
    "    return img\n",
    "\n",
    "def get_dataset(files, augment=None, shuffle=False, repeat=False, \n",
    "                labeled=True, return_image_names=True, batch_size=16, dim=256):\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    \n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(1024*8)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "        \n",
    "    if labeled: \n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n",
    "                    num_parallel_calls=AUTO)      \n",
    "    \n",
    "    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, dim=dim), \n",
    "                                               imgname_or_label), num_parallel_calls=AUTO)\n",
    "    \n",
    "    ds = ds.batch(batch_size * REPLICAS)\n",
    "    ds = ds.prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "\n",
    "def get_dataset_sampling(files, augment=None, shuffle=False, repeat=False, \n",
    "                         labeled=True, return_image_names=True, batch_size=16, dim=256):\n",
    "    \n",
    "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n",
    "    ds = ds.cache()\n",
    "    \n",
    "    if repeat:\n",
    "        ds = ds.repeat()\n",
    "    \n",
    "    if shuffle: \n",
    "        ds = ds.shuffle(1024*8)\n",
    "        opt = tf.data.Options()\n",
    "        opt.experimental_deterministic = False\n",
    "        ds = ds.with_options(opt)\n",
    "        \n",
    "    if labeled: \n",
    "        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    else:\n",
    "        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n",
    "                    num_parallel_calls=AUTO)      \n",
    "    \n",
    "    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, dim=dim), \n",
    "                                               imgname_or_label), num_parallel_calls=AUTO)\n",
    "    \n",
    "    return ds\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n",
    "         for filename in filenames]\n",
    "    return np.sum(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate schedule: 5e-06 to 0.00032 to 1.42e-06\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def lrfn(epoch):\n",
    "    lr_start   = 0.000005\n",
    "    lr_max     = 0.00000125 * REPLICAS * config['BATCH_SIZE']\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 15 #5\n",
    "    lr_sus_ep  = 5\n",
    "    lr_decay   = 0.9 #0.8\n",
    "\n",
    "    if epoch < lr_ramp_ep:\n",
    "        lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "    elif epoch < lr_ramp_ep + lr_sus_ep:\n",
    "        lr = lr_max\n",
    "    else:\n",
    "        lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        \n",
    "    return lr\n",
    "\n",
    "def get_lr_callback():\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n",
    "    return lr_callback\n",
    "\n",
    "total_steps = config['EPOCHS'] * 7\n",
    "rng = [i for i in range(0, total_steps)]\n",
    "y = [lrfn(x) for x in rng]\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(20, 6))\n",
    "plt.plot(rng, y)\n",
    "print(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bias\n",
      "6171\n",
      "43340\n",
      "[-1.9492151]\n",
      "Class weight\n",
      "{0: 0.38216428241808953, 1: 2.6840058337384542}\n"
     ]
    }
   ],
   "source": [
    "# Positive dist (datasets):\n",
    "# Data: Pos | Neg\n",
    "# 2020: 584 | 32108\n",
    "# 2018: 1627 | 11232\n",
    "# 2019: 2858 | 9555\n",
    "# Positive dist (upsampled):\n",
    "# 2020: 581\n",
    "# New: 580\n",
    "# 2018: 1614\n",
    "# 2019: 1185\n",
    "# Initial bias\n",
    "pos = (584 + 1627) + (581 + 580 + 1614 + 1185)\n",
    "neg = 32108 + 11232\n",
    "initial_bias = np.log([pos/neg])\n",
    "print('Bias')\n",
    "print(pos)\n",
    "print(neg)\n",
    "print(initial_bias)\n",
    "\n",
    "# class weights\n",
    "total = len(train)\n",
    "weight_for_0 = (1 / neg)*(total)/2.0 \n",
    "weight_for_1 = (1 / pos)*(total)/2.0\n",
    "\n",
    "class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "print('Class weight')\n",
    "print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(input_shape=(256, 256, 3)):\n",
    "    input_image = L.Input(shape=input_shape, name='input_image')\n",
    "    base_model = efn.EfficientNetB4(input_shape=input_shape, \n",
    "                                    weights=config['BASE_MODEL_WEIGHTS'], \n",
    "                                    include_top=False)\n",
    "\n",
    "    x = base_model(input_image)\n",
    "    x = L.GlobalAveragePooling2D()(x)\n",
    "    output = L.Dense(1, activation='sigmoid', name='output')(x)\n",
    "\n",
    "    model = Model(inputs=input_image, outputs=output)\n",
    "\n",
    "    opt = optimizers.Adam(learning_rate=0.001)\n",
    "    loss = losses.BinaryCrossentropy(label_smoothing=0.05)\n",
    "    model.compile(optimizer=opt, loss=loss, metrics=['AUC'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FOLD: 1\n",
      "TRAIN: [ 1  2  3  4  5  6  7  8 10 12 13 14] VALID: [ 0  9 11]\n",
      "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b4_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
      "71892992/71892840 [==============================] - 1s 0us/step\n",
      "Epoch 1/84\n",
      "24/23 - 36s - auc: 0.5168 - loss: 0.6991 - val_auc: 0.5417 - val_loss: 0.6819 - lr: 5.0000e-06\n",
      "Epoch 2/84\n",
      "24/23 - 15s - auc: 0.7097 - loss: 0.6378 - val_auc: 0.6335 - val_loss: 0.5066 - lr: 2.6000e-05\n",
      "Epoch 3/84\n",
      "24/23 - 15s - auc: 0.8419 - loss: 0.5291 - val_auc: 0.6660 - val_loss: 0.3569 - lr: 4.7000e-05\n",
      "Epoch 4/84\n",
      "24/23 - 15s - auc: 0.8722 - loss: 0.4734 - val_auc: 0.6754 - val_loss: 0.3099 - lr: 6.8000e-05\n",
      "Epoch 5/84\n",
      "24/23 - 15s - auc: 0.8889 - loss: 0.4493 - val_auc: 0.6902 - val_loss: 0.2699 - lr: 8.9000e-05\n",
      "Epoch 6/84\n",
      "24/23 - 15s - auc: 0.9169 - loss: 0.4058 - val_auc: 0.7574 - val_loss: 0.2517 - lr: 1.1000e-04\n",
      "Epoch 7/84\n",
      "24/23 - 15s - auc: 0.9264 - loss: 0.3879 - val_auc: 0.7994 - val_loss: 0.2330 - lr: 1.3100e-04\n",
      "Epoch 8/84\n",
      "24/23 - 15s - auc: 0.9379 - loss: 0.3647 - val_auc: 0.8218 - val_loss: 0.2189 - lr: 1.5200e-04\n",
      "Epoch 9/84\n",
      "24/23 - 12s - auc: 0.9366 - loss: 0.3674 - val_auc: 0.8489 - val_loss: 0.2333 - lr: 1.7300e-04\n",
      "Epoch 10/84\n",
      "24/23 - 12s - auc: 0.9333 - loss: 0.3751 - val_auc: 0.8684 - val_loss: 0.2220 - lr: 1.9400e-04\n",
      "Epoch 11/84\n",
      "24/23 - 12s - auc: 0.9207 - loss: 0.3992 - val_auc: 0.8802 - val_loss: 0.2766 - lr: 2.1500e-04\n",
      "Epoch 12/84\n",
      "24/23 - 12s - auc: 0.9275 - loss: 0.3868 - val_auc: 0.8873 - val_loss: 0.2261 - lr: 2.3600e-04\n",
      "Epoch 13/84\n",
      "24/23 - 13s - auc: 0.9360 - loss: 0.3699 - val_auc: 0.8898 - val_loss: 0.2501 - lr: 2.5700e-04\n",
      "Epoch 14/84\n",
      "24/23 - 10s - auc: 0.9382 - loss: 0.3663 - val_auc: 0.8740 - val_loss: 0.2600 - lr: 2.7800e-04\n",
      "Epoch 15/84\n",
      "24/23 - 10s - auc: 0.9350 - loss: 0.3727 - val_auc: 0.8887 - val_loss: 0.2568 - lr: 2.9900e-04\n",
      "Epoch 16/84\n",
      "24/23 - 13s - auc: 0.9572 - loss: 0.3237 - val_auc: 0.8730 - val_loss: 0.1974 - lr: 3.2000e-04\n",
      "Epoch 17/84\n",
      "24/23 - 12s - auc: 0.9614 - loss: 0.3126 - val_auc: 0.8973 - val_loss: 0.2538 - lr: 3.2000e-04\n",
      "Epoch 18/84\n",
      "24/23 - 14s - auc: 0.9683 - loss: 0.2933 - val_auc: 0.9037 - val_loss: 0.2135 - lr: 3.2000e-04\n",
      "Epoch 19/84\n",
      "24/23 - 10s - auc: 0.9711 - loss: 0.2858 - val_auc: 0.8971 - val_loss: 0.2203 - lr: 3.2000e-04\n",
      "Epoch 20/84\n",
      "24/23 - 10s - auc: 0.9601 - loss: 0.3159 - val_auc: 0.8941 - val_loss: 0.2723 - lr: 3.2000e-04\n",
      "Epoch 21/84\n",
      "24/23 - 13s - auc: 0.9538 - loss: 0.3323 - val_auc: 0.9208 - val_loss: 0.2402 - lr: 3.2000e-04\n",
      "Epoch 22/84\n",
      "24/23 - 10s - auc: 0.9593 - loss: 0.3188 - val_auc: 0.9039 - val_loss: 0.2615 - lr: 2.8810e-04\n",
      "Epoch 23/84\n",
      "24/23 - 12s - auc: 0.9633 - loss: 0.3081 - val_auc: 0.8932 - val_loss: 0.1972 - lr: 2.5939e-04\n",
      "Epoch 24/84\n",
      "24/23 - 10s - auc: 0.9622 - loss: 0.3102 - val_auc: 0.8890 - val_loss: 0.2031 - lr: 2.3355e-04\n",
      "Epoch 25/84\n",
      "24/23 - 10s - auc: 0.9694 - loss: 0.2924 - val_auc: 0.8923 - val_loss: 0.2056 - lr: 2.1030e-04\n",
      "Epoch 26/84\n",
      "24/23 - 12s - auc: 0.9750 - loss: 0.2731 - val_auc: 0.8999 - val_loss: 0.1905 - lr: 1.8937e-04\n",
      "Epoch 27/84\n",
      "24/23 - 10s - auc: 0.9793 - loss: 0.2576 - val_auc: 0.8912 - val_loss: 0.1923 - lr: 1.7053e-04\n",
      "Epoch 28/84\n",
      "24/23 - 10s - auc: 0.9833 - loss: 0.2425 - val_auc: 0.8981 - val_loss: 0.1938 - lr: 1.5358e-04\n",
      "Epoch 29/84\n",
      "24/23 - 12s - auc: 0.9850 - loss: 0.2365 - val_auc: 0.8948 - val_loss: 0.1894 - lr: 1.3832e-04\n",
      "Epoch 30/84\n",
      "24/23 - 10s - auc: 0.9760 - loss: 0.2678 - val_auc: 0.8926 - val_loss: 0.2054 - lr: 1.2459e-04\n",
      "Epoch 31/84\n",
      "24/23 - 10s - auc: 0.9768 - loss: 0.2678 - val_auc: 0.8963 - val_loss: 0.2076 - lr: 1.1223e-04\n",
      "Epoch 32/84\n",
      "24/23 - 10s - auc: 0.9795 - loss: 0.2577 - val_auc: 0.9050 - val_loss: 0.1984 - lr: 1.0111e-04\n",
      "Epoch 33/84\n",
      "24/23 - 10s - auc: 0.9788 - loss: 0.2590 - val_auc: 0.9045 - val_loss: 0.2034 - lr: 9.1095e-05\n",
      "Epoch 34/84\n",
      "24/23 - 10s - auc: 0.9804 - loss: 0.2561 - val_auc: 0.9015 - val_loss: 0.2128 - lr: 8.2086e-05\n",
      "Epoch 35/84\n",
      "24/23 - 10s - auc: 0.9828 - loss: 0.2458 - val_auc: 0.9043 - val_loss: 0.2070 - lr: 7.3977e-05\n",
      "Epoch 36/84\n",
      "24/23 - 10s - auc: 0.9879 - loss: 0.2231 - val_auc: 0.8945 - val_loss: 0.1963 - lr: 6.6679e-05\n",
      "Epoch 37/84\n",
      "24/23 - 10s - auc: 0.9896 - loss: 0.2160 - val_auc: 0.8980 - val_loss: 0.1957 - lr: 6.0111e-05\n",
      "Epoch 38/84\n",
      "24/23 - 10s - auc: 0.9895 - loss: 0.2140 - val_auc: 0.8966 - val_loss: 0.1919 - lr: 5.4200e-05\n",
      "Epoch 39/84\n",
      "24/23 - 10s - auc: 0.9861 - loss: 0.2292 - val_auc: 0.8910 - val_loss: 0.1909 - lr: 4.8880e-05\n",
      "Epoch 40/84\n",
      "24/23 - 10s - auc: 0.9837 - loss: 0.2411 - val_auc: 0.8879 - val_loss: 0.1896 - lr: 4.4092e-05\n",
      "Epoch 41/84\n",
      "24/23 - 10s - auc: 0.9827 - loss: 0.2463 - val_auc: 0.8902 - val_loss: 0.1938 - lr: 3.9783e-05\n",
      "Epoch 42/84\n",
      "24/23 - 10s - auc: 0.9865 - loss: 0.2325 - val_auc: 0.8936 - val_loss: 0.1902 - lr: 3.5905e-05\n",
      "Epoch 43/84\n",
      "24/23 - 10s - auc: 0.9856 - loss: 0.2348 - val_auc: 0.8961 - val_loss: 0.1955 - lr: 3.2414e-05\n",
      "Epoch 44/84\n",
      "24/23 - 10s - auc: 0.9836 - loss: 0.2438 - val_auc: 0.8836 - val_loss: 0.1938 - lr: 2.9273e-05\n",
      "Epoch 45/84\n",
      "24/23 - 10s - auc: 0.9872 - loss: 0.2269 - val_auc: 0.8925 - val_loss: 0.1980 - lr: 2.6445e-05\n",
      "Epoch 46/84\n",
      "24/23 - 10s - auc: 0.9907 - loss: 0.2124 - val_auc: 0.8926 - val_loss: 0.1991 - lr: 2.3901e-05\n",
      "Epoch 47/84\n",
      "24/23 - 10s - auc: 0.9925 - loss: 0.2027 - val_auc: 0.8957 - val_loss: 0.1997 - lr: 2.1611e-05\n",
      "Epoch 48/84\n",
      "24/23 - 10s - auc: 0.9907 - loss: 0.2109 - val_auc: 0.8858 - val_loss: 0.1945 - lr: 1.9550e-05\n",
      "Epoch 49/84\n",
      "24/23 - 10s - auc: 0.9914 - loss: 0.2092 - val_auc: 0.8910 - val_loss: 0.1975 - lr: 1.7695e-05\n",
      "Epoch 50/84\n",
      "24/23 - 10s - auc: 0.9863 - loss: 0.2302 - val_auc: 0.8826 - val_loss: 0.1911 - lr: 1.6025e-05\n",
      "Epoch 51/84\n",
      "24/23 - 10s - auc: 0.9869 - loss: 0.2295 - val_auc: 0.8824 - val_loss: 0.1911 - lr: 1.4523e-05\n",
      "Epoch 52/84\n",
      "24/23 - 10s - auc: 0.9864 - loss: 0.2295 - val_auc: 0.8826 - val_loss: 0.1920 - lr: 1.3171e-05\n",
      "Epoch 53/84\n",
      "24/23 - 10s - auc: 0.9863 - loss: 0.2317 - val_auc: 0.8810 - val_loss: 0.1943 - lr: 1.1953e-05\n",
      "Epoch 54/84\n",
      "24/23 - 10s - auc: 0.9859 - loss: 0.2332 - val_auc: 0.8823 - val_loss: 0.1959 - lr: 1.0858e-05\n",
      "Epoch 55/84\n",
      "24/23 - 10s - auc: 0.9896 - loss: 0.2188 - val_auc: 0.8876 - val_loss: 0.1985 - lr: 9.8723e-06\n",
      "Epoch 56/84\n",
      "24/23 - 10s - auc: 0.9907 - loss: 0.2113 - val_auc: 0.8922 - val_loss: 0.1993 - lr: 8.9851e-06\n",
      "Epoch 57/84\n",
      "24/23 - 10s - auc: 0.9926 - loss: 0.2019 - val_auc: 0.8965 - val_loss: 0.2009 - lr: 8.1866e-06\n",
      "Epoch 58/84\n",
      "24/23 - 10s - auc: 0.9922 - loss: 0.2036 - val_auc: 0.8905 - val_loss: 0.1984 - lr: 7.4679e-06\n",
      "Epoch 59/84\n",
      "24/23 - 11s - auc: 0.9903 - loss: 0.2124 - val_auc: 0.8890 - val_loss: 0.1980 - lr: 6.8211e-06\n",
      "Epoch 60/84\n",
      "24/23 - 10s - auc: 0.9891 - loss: 0.2206 - val_auc: 0.8876 - val_loss: 0.1957 - lr: 6.2390e-06\n",
      "Epoch 61/84\n",
      "24/23 - 10s - auc: 0.9878 - loss: 0.2265 - val_auc: 0.8824 - val_loss: 0.1937 - lr: 5.7151e-06\n",
      "Epoch 62/84\n",
      "24/23 - 10s - auc: 0.9882 - loss: 0.2239 - val_auc: 0.8830 - val_loss: 0.1932 - lr: 5.2436e-06\n",
      "Epoch 63/84\n",
      "24/23 - 10s - auc: 0.9862 - loss: 0.2319 - val_auc: 0.8858 - val_loss: 0.1937 - lr: 4.8192e-06\n",
      "Epoch 64/84\n",
      "24/23 - 10s - auc: 0.9866 - loss: 0.2306 - val_auc: 0.8875 - val_loss: 0.1941 - lr: 4.4373e-06\n",
      "Epoch 65/84\n",
      "24/23 - 10s - auc: 0.9904 - loss: 0.2144 - val_auc: 0.8898 - val_loss: 0.1945 - lr: 4.0936e-06\n",
      "Epoch 66/84\n",
      "24/23 - 10s - auc: 0.9909 - loss: 0.2090 - val_auc: 0.8937 - val_loss: 0.1962 - lr: 3.7842e-06\n",
      "Epoch 67/84\n",
      "24/23 - 10s - auc: 0.9928 - loss: 0.2026 - val_auc: 0.8920 - val_loss: 0.1964 - lr: 3.5058e-06\n",
      "Epoch 68/84\n",
      "24/23 - 10s - auc: 0.9918 - loss: 0.2057 - val_auc: 0.8887 - val_loss: 0.1968 - lr: 3.2552e-06\n",
      "Epoch 69/84\n",
      "24/23 - 10s - auc: 0.9917 - loss: 0.2072 - val_auc: 0.8901 - val_loss: 0.1968 - lr: 3.0297e-06\n",
      "Epoch 70/84\n",
      "24/23 - 10s - auc: 0.9881 - loss: 0.2246 - val_auc: 0.8901 - val_loss: 0.1950 - lr: 2.8267e-06\n",
      "Epoch 71/84\n",
      "24/23 - 10s - auc: 0.9886 - loss: 0.2234 - val_auc: 0.8849 - val_loss: 0.1937 - lr: 2.6441e-06\n",
      "Epoch 72/84\n",
      "24/23 - 10s - auc: 0.9887 - loss: 0.2215 - val_auc: 0.8838 - val_loss: 0.1930 - lr: 2.4796e-06\n",
      "Epoch 73/84\n",
      "24/23 - 10s - auc: 0.9877 - loss: 0.2243 - val_auc: 0.8836 - val_loss: 0.1932 - lr: 2.3317e-06\n",
      "Epoch 74/84\n",
      "24/23 - 10s - auc: 0.9879 - loss: 0.2243 - val_auc: 0.8854 - val_loss: 0.1925 - lr: 2.1985e-06\n",
      "Epoch 75/84\n",
      "24/23 - 10s - auc: 0.9905 - loss: 0.2137 - val_auc: 0.8867 - val_loss: 0.1928 - lr: 2.0787e-06\n",
      "Epoch 76/84\n",
      "24/23 - 10s - auc: 0.9927 - loss: 0.2013 - val_auc: 0.8854 - val_loss: 0.1936 - lr: 1.9708e-06\n",
      "Epoch 77/84\n",
      "24/23 - 10s - auc: 0.9934 - loss: 0.1979 - val_auc: 0.8869 - val_loss: 0.1947 - lr: 1.8737e-06\n",
      "Epoch 78/84\n",
      "24/23 - 10s - auc: 0.9926 - loss: 0.2017 - val_auc: 0.8853 - val_loss: 0.1956 - lr: 1.7863e-06\n",
      "Epoch 79/84\n",
      "24/23 - 10s - auc: 0.9908 - loss: 0.2115 - val_auc: 0.8874 - val_loss: 0.1956 - lr: 1.7077e-06\n",
      "Epoch 80/84\n",
      "24/23 - 10s - auc: 0.9865 - loss: 0.2289 - val_auc: 0.8870 - val_loss: 0.1947 - lr: 1.6369e-06\n",
      "Epoch 81/84\n",
      "24/23 - 10s - auc: 0.9882 - loss: 0.2219 - val_auc: 0.8853 - val_loss: 0.1940 - lr: 1.5732e-06\n",
      "Epoch 82/84\n",
      "24/23 - 10s - auc: 0.9875 - loss: 0.2264 - val_auc: 0.8839 - val_loss: 0.1936 - lr: 1.5159e-06\n",
      "Epoch 83/84\n",
      "24/23 - 10s - auc: 0.9876 - loss: 0.2254 - val_auc: 0.8865 - val_loss: 0.1935 - lr: 1.4643e-06\n",
      "Epoch 84/84\n",
      "24/23 - 10s - auc: 0.9896 - loss: 0.2177 - val_auc: 0.8884 - val_loss: 0.1937 - lr: 1.4179e-06\n",
      "Predicting OOF with TTA (AUC)...\n",
      "160/159 - 45s\n",
      "Predicting Test with TTA (AUC)...\n",
      "269/268 - 77s\n",
      "Predicting OOF with TTA (Loss)...\n",
      "160/159 - 46s\n",
      "Predicting Test with TTA (Loss)...\n",
      "269/268 - 78s\n",
      "#### FOLD 1 OOF AUC = 0.921, with TTA (Loss) = 0.914, with TTA (AUC) = 0.922, with TTA (Blend) = 0.926\n",
      "\n",
      "FOLD: 2\n",
      "TRAIN: [ 0  1  2  3  4  6  7  9 10 11 12 14] VALID: [ 5  8 13]\n",
      "Epoch 1/84\n",
      "24/23 - 35s - auc: 0.5436 - loss: 0.6883 - val_auc: 0.4341 - val_loss: 0.7872 - lr: 5.0000e-06\n",
      "Epoch 2/84\n",
      "24/23 - 15s - auc: 0.7425 - loss: 0.6164 - val_auc: 0.5488 - val_loss: 0.5960 - lr: 2.6000e-05\n",
      "Epoch 3/84\n",
      "24/23 - 15s - auc: 0.8448 - loss: 0.5207 - val_auc: 0.6219 - val_loss: 0.4239 - lr: 4.7000e-05\n",
      "Epoch 4/84\n",
      "24/23 - 15s - auc: 0.8769 - loss: 0.4673 - val_auc: 0.6608 - val_loss: 0.3478 - lr: 6.8000e-05\n",
      "Epoch 5/84\n",
      "24/23 - 15s - auc: 0.8768 - loss: 0.4658 - val_auc: 0.7103 - val_loss: 0.3007 - lr: 8.9000e-05\n",
      "Epoch 6/84\n",
      "24/23 - 15s - auc: 0.9099 - loss: 0.4182 - val_auc: 0.7562 - val_loss: 0.2840 - lr: 1.1000e-04\n",
      "Epoch 7/84\n",
      "24/23 - 15s - auc: 0.9283 - loss: 0.3868 - val_auc: 0.8068 - val_loss: 0.2222 - lr: 1.3100e-04\n",
      "Epoch 8/84\n",
      "24/23 - 15s - auc: 0.9348 - loss: 0.3724 - val_auc: 0.8209 - val_loss: 0.2188 - lr: 1.5200e-04\n",
      "Epoch 9/84\n",
      "24/23 - 12s - auc: 0.9391 - loss: 0.3639 - val_auc: 0.8484 - val_loss: 0.2230 - lr: 1.7300e-04\n",
      "Epoch 10/84\n",
      "24/23 - 12s - auc: 0.9430 - loss: 0.3555 - val_auc: 0.8550 - val_loss: 0.2496 - lr: 1.9400e-04\n",
      "Epoch 11/84\n",
      "24/23 - 12s - auc: 0.9426 - loss: 0.3569 - val_auc: 0.8763 - val_loss: 0.3074 - lr: 2.1500e-04\n",
      "Epoch 12/84\n",
      "24/23 - 10s - auc: 0.9374 - loss: 0.3678 - val_auc: 0.8704 - val_loss: 0.2609 - lr: 2.3600e-04\n",
      "Epoch 13/84\n",
      "24/23 - 12s - auc: 0.9330 - loss: 0.3768 - val_auc: 0.8454 - val_loss: 0.2104 - lr: 2.5700e-04\n",
      "Epoch 14/84\n",
      "24/23 - 10s - auc: 0.9372 - loss: 0.3675 - val_auc: 0.8632 - val_loss: 0.2293 - lr: 2.7800e-04\n",
      "Epoch 15/84\n",
      "24/23 - 12s - auc: 0.9411 - loss: 0.3615 - val_auc: 0.8958 - val_loss: 0.2711 - lr: 2.9900e-04\n",
      "Epoch 16/84\n",
      "24/23 - 12s - auc: 0.9487 - loss: 0.3440 - val_auc: 0.8970 - val_loss: 0.2764 - lr: 3.2000e-04\n",
      "Epoch 17/84\n",
      "24/23 - 10s - auc: 0.9579 - loss: 0.3212 - val_auc: 0.8720 - val_loss: 0.2508 - lr: 3.2000e-04\n",
      "Epoch 18/84\n",
      "24/23 - 12s - auc: 0.9681 - loss: 0.2962 - val_auc: 0.8988 - val_loss: 0.2605 - lr: 3.2000e-04\n",
      "Epoch 19/84\n",
      "24/23 - 10s - auc: 0.9653 - loss: 0.3026 - val_auc: 0.8846 - val_loss: 0.2473 - lr: 3.2000e-04\n",
      "Epoch 20/84\n",
      "24/23 - 10s - auc: 0.9707 - loss: 0.2875 - val_auc: 0.8842 - val_loss: 0.2146 - lr: 3.2000e-04\n",
      "Epoch 21/84\n",
      "24/23 - 10s - auc: 0.9653 - loss: 0.3022 - val_auc: 0.8720 - val_loss: 0.2161 - lr: 3.2000e-04\n",
      "Epoch 22/84\n",
      "24/23 - 10s - auc: 0.9609 - loss: 0.3145 - val_auc: 0.8858 - val_loss: 0.2274 - lr: 2.8810e-04\n",
      "Epoch 23/84\n",
      "24/23 - 10s - auc: 0.9682 - loss: 0.2947 - val_auc: 0.8444 - val_loss: 0.2256 - lr: 2.5939e-04\n",
      "Epoch 24/84\n",
      "24/23 - 10s - auc: 0.9661 - loss: 0.2992 - val_auc: 0.8816 - val_loss: 0.2527 - lr: 2.3355e-04\n",
      "Epoch 25/84\n",
      "24/23 - 10s - auc: 0.9678 - loss: 0.2966 - val_auc: 0.8884 - val_loss: 0.2586 - lr: 2.1030e-04\n",
      "Epoch 26/84\n",
      "24/23 - 10s - auc: 0.9743 - loss: 0.2745 - val_auc: 0.8807 - val_loss: 0.2125 - lr: 1.8937e-04\n",
      "Epoch 27/84\n",
      "24/23 - 10s - auc: 0.9804 - loss: 0.2541 - val_auc: 0.8941 - val_loss: 0.2192 - lr: 1.7053e-04\n",
      "Epoch 28/84\n",
      "24/23 - 12s - auc: 0.9830 - loss: 0.2458 - val_auc: 0.8911 - val_loss: 0.2066 - lr: 1.5358e-04\n",
      "Epoch 29/84\n",
      "24/23 - 10s - auc: 0.9816 - loss: 0.2501 - val_auc: 0.8721 - val_loss: 0.2111 - lr: 1.3832e-04\n",
      "Epoch 30/84\n",
      "24/23 - 12s - auc: 0.9843 - loss: 0.2387 - val_auc: 0.8771 - val_loss: 0.2002 - lr: 1.2459e-04\n",
      "Epoch 31/84\n",
      "24/23 - 14s - auc: 0.9802 - loss: 0.2542 - val_auc: 0.8787 - val_loss: 0.1920 - lr: 1.1223e-04\n",
      "Epoch 32/84\n",
      "24/23 - 10s - auc: 0.9787 - loss: 0.2609 - val_auc: 0.8837 - val_loss: 0.2089 - lr: 1.0111e-04\n",
      "Epoch 33/84\n",
      "24/23 - 10s - auc: 0.9825 - loss: 0.2490 - val_auc: 0.8697 - val_loss: 0.1941 - lr: 9.1095e-05\n",
      "Epoch 34/84\n",
      "24/23 - 10s - auc: 0.9818 - loss: 0.2488 - val_auc: 0.8587 - val_loss: 0.1989 - lr: 8.2086e-05\n",
      "Epoch 35/84\n",
      "24/23 - 11s - auc: 0.9810 - loss: 0.2527 - val_auc: 0.8788 - val_loss: 0.2084 - lr: 7.3977e-05\n",
      "Epoch 36/84\n",
      "24/23 - 10s - auc: 0.9841 - loss: 0.2405 - val_auc: 0.8883 - val_loss: 0.2074 - lr: 6.6679e-05\n",
      "Epoch 37/84\n",
      "24/23 - 10s - auc: 0.9891 - loss: 0.2212 - val_auc: 0.8763 - val_loss: 0.1995 - lr: 6.0111e-05\n",
      "Epoch 38/84\n",
      "24/23 - 10s - auc: 0.9889 - loss: 0.2190 - val_auc: 0.8689 - val_loss: 0.1960 - lr: 5.4200e-05\n",
      "Epoch 39/84\n",
      "24/23 - 10s - auc: 0.9881 - loss: 0.2212 - val_auc: 0.8642 - val_loss: 0.2003 - lr: 4.8880e-05\n",
      "Epoch 40/84\n",
      "24/23 - 10s - auc: 0.9892 - loss: 0.2179 - val_auc: 0.8881 - val_loss: 0.2045 - lr: 4.4092e-05\n",
      "Epoch 41/84\n",
      "24/23 - 10s - auc: 0.9874 - loss: 0.2290 - val_auc: 0.8753 - val_loss: 0.1953 - lr: 3.9783e-05\n",
      "Epoch 42/84\n",
      "24/23 - 10s - auc: 0.9845 - loss: 0.2392 - val_auc: 0.8735 - val_loss: 0.1982 - lr: 3.5905e-05\n",
      "Epoch 43/84\n",
      "24/23 - 10s - auc: 0.9874 - loss: 0.2288 - val_auc: 0.8614 - val_loss: 0.1957 - lr: 3.2414e-05\n",
      "Epoch 44/84\n",
      "24/23 - 10s - auc: 0.9868 - loss: 0.2315 - val_auc: 0.8563 - val_loss: 0.2001 - lr: 2.9273e-05\n",
      "Epoch 45/84\n",
      "24/23 - 10s - auc: 0.9863 - loss: 0.2309 - val_auc: 0.8474 - val_loss: 0.1996 - lr: 2.6445e-05\n",
      "Epoch 46/84\n",
      "24/23 - 10s - auc: 0.9888 - loss: 0.2199 - val_auc: 0.8651 - val_loss: 0.2026 - lr: 2.3901e-05\n",
      "Epoch 47/84\n",
      "24/23 - 10s - auc: 0.9892 - loss: 0.2166 - val_auc: 0.8754 - val_loss: 0.2071 - lr: 2.1611e-05\n",
      "Epoch 48/84\n",
      "24/23 - 10s - auc: 0.9904 - loss: 0.2134 - val_auc: 0.8740 - val_loss: 0.2031 - lr: 1.9550e-05\n",
      "Epoch 49/84\n",
      "24/23 - 10s - auc: 0.9897 - loss: 0.2167 - val_auc: 0.8606 - val_loss: 0.1954 - lr: 1.7695e-05\n",
      "Epoch 50/84\n",
      "24/23 - 10s - auc: 0.9923 - loss: 0.2029 - val_auc: 0.8699 - val_loss: 0.1970 - lr: 1.6025e-05\n",
      "Epoch 51/84\n",
      "24/23 - 10s - auc: 0.9885 - loss: 0.2201 - val_auc: 0.8725 - val_loss: 0.1964 - lr: 1.4523e-05\n",
      "Epoch 52/84\n",
      "24/23 - 10s - auc: 0.9880 - loss: 0.2224 - val_auc: 0.8660 - val_loss: 0.1963 - lr: 1.3171e-05\n",
      "Epoch 53/84\n",
      "24/23 - 10s - auc: 0.9870 - loss: 0.2276 - val_auc: 0.8581 - val_loss: 0.1977 - lr: 1.1953e-05\n",
      "Epoch 54/84\n",
      "24/23 - 10s - auc: 0.9867 - loss: 0.2287 - val_auc: 0.8560 - val_loss: 0.1967 - lr: 1.0858e-05\n",
      "Epoch 55/84\n",
      "24/23 - 10s - auc: 0.9889 - loss: 0.2190 - val_auc: 0.8600 - val_loss: 0.1961 - lr: 9.8723e-06\n",
      "Epoch 56/84\n",
      "24/23 - 10s - auc: 0.9895 - loss: 0.2159 - val_auc: 0.8643 - val_loss: 0.1972 - lr: 8.9851e-06\n",
      "Epoch 57/84\n",
      "24/23 - 10s - auc: 0.9920 - loss: 0.2029 - val_auc: 0.8637 - val_loss: 0.1979 - lr: 8.1866e-06\n",
      "Epoch 58/84\n",
      "24/23 - 10s - auc: 0.9911 - loss: 0.2101 - val_auc: 0.8699 - val_loss: 0.1991 - lr: 7.4679e-06\n",
      "Epoch 59/84\n",
      "24/23 - 10s - auc: 0.9907 - loss: 0.2119 - val_auc: 0.8702 - val_loss: 0.1988 - lr: 6.8211e-06\n",
      "Epoch 60/84\n",
      "24/23 - 10s - auc: 0.9902 - loss: 0.2120 - val_auc: 0.8658 - val_loss: 0.1979 - lr: 6.2390e-06\n",
      "Epoch 61/84\n",
      "24/23 - 10s - auc: 0.9880 - loss: 0.2253 - val_auc: 0.8688 - val_loss: 0.1964 - lr: 5.7151e-06\n",
      "Epoch 62/84\n",
      "24/23 - 10s - auc: 0.9880 - loss: 0.2228 - val_auc: 0.8672 - val_loss: 0.1953 - lr: 5.2436e-06\n",
      "Epoch 63/84\n",
      "24/23 - 10s - auc: 0.9903 - loss: 0.2137 - val_auc: 0.8638 - val_loss: 0.1949 - lr: 4.8192e-06\n",
      "Epoch 64/84\n",
      "24/23 - 10s - auc: 0.9858 - loss: 0.2327 - val_auc: 0.8665 - val_loss: 0.1959 - lr: 4.4373e-06\n",
      "Epoch 65/84\n",
      "24/23 - 10s - auc: 0.9865 - loss: 0.2275 - val_auc: 0.8654 - val_loss: 0.1965 - lr: 4.0936e-06\n",
      "Epoch 66/84\n",
      "24/23 - 10s - auc: 0.9915 - loss: 0.2080 - val_auc: 0.8674 - val_loss: 0.1976 - lr: 3.7842e-06\n",
      "Epoch 67/84\n",
      "24/23 - 10s - auc: 0.9930 - loss: 0.1986 - val_auc: 0.8689 - val_loss: 0.1985 - lr: 3.5058e-06\n",
      "Epoch 68/84\n",
      "24/23 - 10s - auc: 0.9929 - loss: 0.2013 - val_auc: 0.8685 - val_loss: 0.1991 - lr: 3.2552e-06\n",
      "Epoch 69/84\n",
      "24/23 - 10s - auc: 0.9924 - loss: 0.2025 - val_auc: 0.8728 - val_loss: 0.1993 - lr: 3.0297e-06\n",
      "Epoch 70/84\n",
      "24/23 - 10s - auc: 0.9900 - loss: 0.2125 - val_auc: 0.8710 - val_loss: 0.1993 - lr: 2.8267e-06\n",
      "Epoch 71/84\n",
      "24/23 - 10s - auc: 0.9886 - loss: 0.2217 - val_auc: 0.8730 - val_loss: 0.1982 - lr: 2.6441e-06\n",
      "Epoch 72/84\n",
      "24/23 - 10s - auc: 0.9886 - loss: 0.2196 - val_auc: 0.8686 - val_loss: 0.1969 - lr: 2.4796e-06\n",
      "Epoch 73/84\n",
      "24/23 - 10s - auc: 0.9875 - loss: 0.2237 - val_auc: 0.8659 - val_loss: 0.1964 - lr: 2.3317e-06\n",
      "Epoch 74/84\n",
      "24/23 - 10s - auc: 0.9879 - loss: 0.2240 - val_auc: 0.8605 - val_loss: 0.1956 - lr: 2.1985e-06\n",
      "Epoch 75/84\n",
      "24/23 - 10s - auc: 0.9892 - loss: 0.2179 - val_auc: 0.8615 - val_loss: 0.1952 - lr: 2.0787e-06\n",
      "Epoch 76/84\n",
      "24/23 - 10s - auc: 0.9916 - loss: 0.2056 - val_auc: 0.8591 - val_loss: 0.1954 - lr: 1.9708e-06\n",
      "Epoch 77/84\n",
      "24/23 - 10s - auc: 0.9927 - loss: 0.2017 - val_auc: 0.8589 - val_loss: 0.1962 - lr: 1.8737e-06\n",
      "Epoch 78/84\n",
      "24/23 - 10s - auc: 0.9905 - loss: 0.2087 - val_auc: 0.8618 - val_loss: 0.1971 - lr: 1.7863e-06\n",
      "Epoch 79/84\n",
      "24/23 - 10s - auc: 0.9930 - loss: 0.1995 - val_auc: 0.8631 - val_loss: 0.1975 - lr: 1.7077e-06\n",
      "Epoch 80/84\n",
      "24/23 - 10s - auc: 0.9901 - loss: 0.2122 - val_auc: 0.8646 - val_loss: 0.1977 - lr: 1.6369e-06\n",
      "Epoch 81/84\n",
      "24/23 - 10s - auc: 0.9886 - loss: 0.2185 - val_auc: 0.8670 - val_loss: 0.1972 - lr: 1.5732e-06\n",
      "Epoch 82/84\n",
      "24/23 - 10s - auc: 0.9894 - loss: 0.2166 - val_auc: 0.8655 - val_loss: 0.1970 - lr: 1.5159e-06\n",
      "Epoch 83/84\n",
      "24/23 - 10s - auc: 0.9878 - loss: 0.2233 - val_auc: 0.8644 - val_loss: 0.1973 - lr: 1.4643e-06\n",
      "Epoch 84/84\n",
      "24/23 - 10s - auc: 0.9879 - loss: 0.2243 - val_auc: 0.8631 - val_loss: 0.1969 - lr: 1.4179e-06\n",
      "Predicting OOF with TTA (AUC)...\n",
      "160/159 - 45s\n",
      "Predicting Test with TTA (AUC)...\n",
      "269/268 - 77s\n",
      "Predicting OOF with TTA (Loss)...\n",
      "160/159 - 46s\n",
      "Predicting Test with TTA (Loss)...\n",
      "269/268 - 78s\n",
      "#### FOLD 2 OOF AUC = 0.899, with TTA (Loss) = 0.896, with TTA (AUC) = 0.897, with TTA (Blend) = 0.911\n",
      "\n",
      "FOLD: 3\n",
      "TRAIN: [ 0  3  4  5  6  7  8  9 10 11 12 13] VALID: [ 1  2 14]\n",
      "Epoch 1/84\n",
      "24/23 - 35s - auc: 0.5841 - loss: 0.6923 - val_auc: 0.6016 - val_loss: 0.5631 - lr: 5.0000e-06\n",
      "Epoch 2/84\n",
      "24/23 - 15s - auc: 0.7605 - loss: 0.6197 - val_auc: 0.6705 - val_loss: 0.4499 - lr: 2.6000e-05\n",
      "Epoch 3/84\n",
      "24/23 - 15s - auc: 0.8394 - loss: 0.5299 - val_auc: 0.6990 - val_loss: 0.3137 - lr: 4.7000e-05\n",
      "Epoch 4/84\n",
      "24/23 - 15s - auc: 0.8703 - loss: 0.4785 - val_auc: 0.7234 - val_loss: 0.2628 - lr: 6.8000e-05\n",
      "Epoch 5/84\n",
      "24/23 - 15s - auc: 0.8723 - loss: 0.4722 - val_auc: 0.7736 - val_loss: 0.2473 - lr: 8.9000e-05\n",
      "Epoch 6/84\n",
      "24/23 - 15s - auc: 0.8923 - loss: 0.4435 - val_auc: 0.7973 - val_loss: 0.2173 - lr: 1.1000e-04\n",
      "Epoch 7/84\n",
      "24/23 - 15s - auc: 0.9106 - loss: 0.4161 - val_auc: 0.8272 - val_loss: 0.2000 - lr: 1.3100e-04\n",
      "Epoch 8/84\n",
      "24/23 - 13s - auc: 0.9352 - loss: 0.3719 - val_auc: 0.8541 - val_loss: 0.2080 - lr: 1.5200e-04\n",
      "Epoch 9/84\n",
      "24/23 - 15s - auc: 0.9467 - loss: 0.3476 - val_auc: 0.8735 - val_loss: 0.1990 - lr: 1.7300e-04\n",
      "Epoch 10/84\n",
      "24/23 - 12s - auc: 0.9575 - loss: 0.3196 - val_auc: 0.8843 - val_loss: 0.2071 - lr: 1.9400e-04\n",
      "Epoch 11/84\n",
      "24/23 - 12s - auc: 0.9459 - loss: 0.3494 - val_auc: 0.8947 - val_loss: 0.2391 - lr: 2.1500e-04\n",
      "Epoch 12/84\n",
      "24/23 - 12s - auc: 0.9300 - loss: 0.3825 - val_auc: 0.9061 - val_loss: 0.2260 - lr: 2.3600e-04\n",
      "Epoch 13/84\n",
      "24/23 - 12s - auc: 0.9291 - loss: 0.3844 - val_auc: 0.9136 - val_loss: 0.2148 - lr: 2.5700e-04\n",
      "Epoch 14/84\n",
      "24/23 - 10s - auc: 0.9357 - loss: 0.3722 - val_auc: 0.9131 - val_loss: 0.2078 - lr: 2.7800e-04\n",
      "Epoch 15/84\n",
      "24/23 - 12s - auc: 0.9295 - loss: 0.3838 - val_auc: 0.9168 - val_loss: 0.2279 - lr: 2.9900e-04\n",
      "Epoch 16/84\n",
      "24/23 - 10s - auc: 0.9404 - loss: 0.3613 - val_auc: 0.9121 - val_loss: 0.2436 - lr: 3.2000e-04\n",
      "Epoch 17/84\n",
      "24/23 - 15s - auc: 0.9544 - loss: 0.3298 - val_auc: 0.9206 - val_loss: 0.1970 - lr: 3.2000e-04\n",
      "Epoch 18/84\n",
      "24/23 - 10s - auc: 0.9654 - loss: 0.3021 - val_auc: 0.9113 - val_loss: 0.1973 - lr: 3.2000e-04\n",
      "Epoch 19/84\n",
      "24/23 - 10s - auc: 0.9706 - loss: 0.2866 - val_auc: 0.9115 - val_loss: 0.2067 - lr: 3.2000e-04\n",
      "Epoch 20/84\n",
      "24/23 - 10s - auc: 0.9758 - loss: 0.2696 - val_auc: 0.9066 - val_loss: 0.2124 - lr: 3.2000e-04\n",
      "Epoch 21/84\n",
      "24/23 - 10s - auc: 0.9662 - loss: 0.2996 - val_auc: 0.9181 - val_loss: 0.2107 - lr: 3.2000e-04\n",
      "Epoch 22/84\n",
      "24/23 - 10s - auc: 0.9656 - loss: 0.3024 - val_auc: 0.9177 - val_loss: 0.2356 - lr: 2.8810e-04\n",
      "Epoch 23/84\n",
      "24/23 - 10s - auc: 0.9613 - loss: 0.3125 - val_auc: 0.9062 - val_loss: 0.2361 - lr: 2.5939e-04\n",
      "Epoch 24/84\n",
      "24/23 - 10s - auc: 0.9594 - loss: 0.3172 - val_auc: 0.9014 - val_loss: 0.2263 - lr: 2.3355e-04\n",
      "Epoch 25/84\n",
      "24/23 - 10s - auc: 0.9640 - loss: 0.3065 - val_auc: 0.9163 - val_loss: 0.2098 - lr: 2.1030e-04\n",
      "Epoch 26/84\n",
      "24/23 - 12s - auc: 0.9729 - loss: 0.2804 - val_auc: 0.9096 - val_loss: 0.1929 - lr: 1.8937e-04\n",
      "Epoch 27/84\n",
      "24/23 - 10s - auc: 0.9736 - loss: 0.2776 - val_auc: 0.9173 - val_loss: 0.2096 - lr: 1.7053e-04\n",
      "Epoch 28/84\n",
      "24/23 - 10s - auc: 0.9823 - loss: 0.2449 - val_auc: 0.9156 - val_loss: 0.2053 - lr: 1.5358e-04\n",
      "Epoch 29/84\n",
      "24/23 - 10s - auc: 0.9842 - loss: 0.2408 - val_auc: 0.8977 - val_loss: 0.1959 - lr: 1.3832e-04\n",
      "Epoch 30/84\n",
      "24/23 - 12s - auc: 0.9847 - loss: 0.2367 - val_auc: 0.8829 - val_loss: 0.1916 - lr: 1.2459e-04\n",
      "Epoch 31/84\n",
      "24/23 - 10s - auc: 0.9820 - loss: 0.2496 - val_auc: 0.9069 - val_loss: 0.2097 - lr: 1.1223e-04\n",
      "Epoch 32/84\n",
      "24/23 - 10s - auc: 0.9780 - loss: 0.2624 - val_auc: 0.8973 - val_loss: 0.1992 - lr: 1.0111e-04\n",
      "Epoch 33/84\n",
      "24/23 - 10s - auc: 0.9788 - loss: 0.2618 - val_auc: 0.9092 - val_loss: 0.2099 - lr: 9.1095e-05\n",
      "Epoch 34/84\n",
      "24/23 - 10s - auc: 0.9812 - loss: 0.2532 - val_auc: 0.8980 - val_loss: 0.2044 - lr: 8.2086e-05\n",
      "Epoch 35/84\n",
      "24/23 - 10s - auc: 0.9770 - loss: 0.2652 - val_auc: 0.9128 - val_loss: 0.2135 - lr: 7.3977e-05\n",
      "Epoch 36/84\n",
      "24/23 - 10s - auc: 0.9827 - loss: 0.2463 - val_auc: 0.9138 - val_loss: 0.1930 - lr: 6.6679e-05\n",
      "Epoch 37/84\n",
      "24/23 - 12s - auc: 0.9844 - loss: 0.2390 - val_auc: 0.9120 - val_loss: 0.1913 - lr: 6.0111e-05\n",
      "Epoch 38/84\n",
      "24/23 - 12s - auc: 0.9880 - loss: 0.2238 - val_auc: 0.8926 - val_loss: 0.1860 - lr: 5.4200e-05\n",
      "Epoch 39/84\n",
      "24/23 - 10s - auc: 0.9916 - loss: 0.2086 - val_auc: 0.8868 - val_loss: 0.1922 - lr: 4.8880e-05\n",
      "Epoch 40/84\n",
      "24/23 - 10s - auc: 0.9903 - loss: 0.2119 - val_auc: 0.8790 - val_loss: 0.1876 - lr: 4.4092e-05\n",
      "Epoch 41/84\n",
      "24/23 - 10s - auc: 0.9858 - loss: 0.2332 - val_auc: 0.8663 - val_loss: 0.1872 - lr: 3.9783e-05\n",
      "Epoch 42/84\n",
      "24/23 - 10s - auc: 0.9843 - loss: 0.2387 - val_auc: 0.8545 - val_loss: 0.1890 - lr: 3.5905e-05\n",
      "Epoch 43/84\n",
      "24/23 - 10s - auc: 0.9834 - loss: 0.2436 - val_auc: 0.8662 - val_loss: 0.1926 - lr: 3.2414e-05\n",
      "Epoch 44/84\n",
      "24/23 - 10s - auc: 0.9844 - loss: 0.2389 - val_auc: 0.8691 - val_loss: 0.1957 - lr: 2.9273e-05\n",
      "Epoch 45/84\n",
      "24/23 - 10s - auc: 0.9812 - loss: 0.2509 - val_auc: 0.8728 - val_loss: 0.1957 - lr: 2.6445e-05\n",
      "Epoch 46/84\n",
      "24/23 - 13s - auc: 0.9870 - loss: 0.2296 - val_auc: 0.8793 - val_loss: 0.1942 - lr: 2.3901e-05\n",
      "Epoch 47/84\n",
      "24/23 - 10s - auc: 0.9888 - loss: 0.2215 - val_auc: 0.8808 - val_loss: 0.1906 - lr: 2.1611e-05\n",
      "Epoch 48/84\n",
      "24/23 - 10s - auc: 0.9924 - loss: 0.2027 - val_auc: 0.8728 - val_loss: 0.1875 - lr: 1.9550e-05\n",
      "Epoch 49/84\n",
      "24/23 - 10s - auc: 0.9922 - loss: 0.2029 - val_auc: 0.8730 - val_loss: 0.1895 - lr: 1.7695e-05\n",
      "Epoch 50/84\n",
      "24/23 - 10s - auc: 0.9906 - loss: 0.2103 - val_auc: 0.8627 - val_loss: 0.1865 - lr: 1.6025e-05\n",
      "Epoch 51/84\n",
      "24/23 - 10s - auc: 0.9882 - loss: 0.2232 - val_auc: 0.8578 - val_loss: 0.1866 - lr: 1.4523e-05\n",
      "Epoch 52/84\n",
      "24/23 - 10s - auc: 0.9873 - loss: 0.2258 - val_auc: 0.8662 - val_loss: 0.1894 - lr: 1.3171e-05\n",
      "Epoch 53/84\n",
      "24/23 - 10s - auc: 0.9844 - loss: 0.2401 - val_auc: 0.8622 - val_loss: 0.1894 - lr: 1.1953e-05\n",
      "Epoch 54/84\n",
      "24/23 - 10s - auc: 0.9865 - loss: 0.2308 - val_auc: 0.8588 - val_loss: 0.1912 - lr: 1.0858e-05\n",
      "Epoch 55/84\n",
      "24/23 - 10s - auc: 0.9845 - loss: 0.2395 - val_auc: 0.8639 - val_loss: 0.1913 - lr: 9.8723e-06\n",
      "Epoch 56/84\n",
      "24/23 - 10s - auc: 0.9893 - loss: 0.2180 - val_auc: 0.8619 - val_loss: 0.1903 - lr: 8.9851e-06\n",
      "Epoch 57/84\n",
      "24/23 - 10s - auc: 0.9889 - loss: 0.2188 - val_auc: 0.8743 - val_loss: 0.1925 - lr: 8.1866e-06\n",
      "Epoch 58/84\n",
      "24/23 - 10s - auc: 0.9930 - loss: 0.1988 - val_auc: 0.8787 - val_loss: 0.1928 - lr: 7.4679e-06\n",
      "Epoch 59/84\n",
      "24/23 - 10s - auc: 0.9934 - loss: 0.1968 - val_auc: 0.8766 - val_loss: 0.1926 - lr: 6.8211e-06\n",
      "Epoch 60/84\n",
      "24/23 - 10s - auc: 0.9918 - loss: 0.2033 - val_auc: 0.8745 - val_loss: 0.1915 - lr: 6.2390e-06\n",
      "Epoch 61/84\n",
      "24/23 - 10s - auc: 0.9892 - loss: 0.2202 - val_auc: 0.8644 - val_loss: 0.1887 - lr: 5.7151e-06\n",
      "Epoch 62/84\n",
      "24/23 - 10s - auc: 0.9862 - loss: 0.2312 - val_auc: 0.8579 - val_loss: 0.1861 - lr: 5.2436e-06\n",
      "Epoch 63/84\n",
      "24/23 - 10s - auc: 0.9875 - loss: 0.2263 - val_auc: 0.8554 - val_loss: 0.1867 - lr: 4.8192e-06\n",
      "Epoch 64/84\n",
      "24/23 - 10s - auc: 0.9849 - loss: 0.2360 - val_auc: 0.8600 - val_loss: 0.1880 - lr: 4.4373e-06\n",
      "Epoch 65/84\n",
      "24/23 - 10s - auc: 0.9868 - loss: 0.2312 - val_auc: 0.8588 - val_loss: 0.1882 - lr: 4.0936e-06\n",
      "Epoch 66/84\n",
      "24/23 - 10s - auc: 0.9880 - loss: 0.2229 - val_auc: 0.8602 - val_loss: 0.1888 - lr: 3.7842e-06\n",
      "Epoch 67/84\n",
      "24/23 - 10s - auc: 0.9920 - loss: 0.2073 - val_auc: 0.8676 - val_loss: 0.1894 - lr: 3.5058e-06\n",
      "Epoch 68/84\n",
      "24/23 - 10s - auc: 0.9929 - loss: 0.2013 - val_auc: 0.8736 - val_loss: 0.1905 - lr: 3.2552e-06\n",
      "Epoch 69/84\n",
      "24/23 - 10s - auc: 0.9948 - loss: 0.1907 - val_auc: 0.8746 - val_loss: 0.1913 - lr: 3.0297e-06\n",
      "Epoch 70/84\n",
      "24/23 - 10s - auc: 0.9903 - loss: 0.2117 - val_auc: 0.8746 - val_loss: 0.1918 - lr: 2.8267e-06\n",
      "Epoch 71/84\n",
      "24/23 - 10s - auc: 0.9893 - loss: 0.2201 - val_auc: 0.8717 - val_loss: 0.1901 - lr: 2.6441e-06\n",
      "Epoch 72/84\n",
      "24/23 - 10s - auc: 0.9868 - loss: 0.2296 - val_auc: 0.8651 - val_loss: 0.1896 - lr: 2.4796e-06\n",
      "Epoch 73/84\n",
      "24/23 - 10s - auc: 0.9885 - loss: 0.2231 - val_auc: 0.8615 - val_loss: 0.1890 - lr: 2.3317e-06\n",
      "Epoch 74/84\n",
      "24/23 - 10s - auc: 0.9849 - loss: 0.2355 - val_auc: 0.8558 - val_loss: 0.1881 - lr: 2.1985e-06\n",
      "Epoch 75/84\n",
      "24/23 - 10s - auc: 0.9833 - loss: 0.2406 - val_auc: 0.8565 - val_loss: 0.1879 - lr: 2.0787e-06\n",
      "Epoch 76/84\n",
      "24/23 - 10s - auc: 0.9904 - loss: 0.2148 - val_auc: 0.8601 - val_loss: 0.1883 - lr: 1.9708e-06\n",
      "Epoch 77/84\n",
      "24/23 - 10s - auc: 0.9904 - loss: 0.2136 - val_auc: 0.8635 - val_loss: 0.1887 - lr: 1.8737e-06\n",
      "Epoch 78/84\n",
      "24/23 - 10s - auc: 0.9921 - loss: 0.2034 - val_auc: 0.8671 - val_loss: 0.1898 - lr: 1.7863e-06\n",
      "Epoch 79/84\n",
      "24/23 - 10s - auc: 0.9938 - loss: 0.1967 - val_auc: 0.8641 - val_loss: 0.1901 - lr: 1.7077e-06\n",
      "Epoch 80/84\n",
      "24/23 - 10s - auc: 0.9890 - loss: 0.2192 - val_auc: 0.8668 - val_loss: 0.1905 - lr: 1.6369e-06\n",
      "Epoch 81/84\n",
      "24/23 - 10s - auc: 0.9893 - loss: 0.2194 - val_auc: 0.8688 - val_loss: 0.1898 - lr: 1.5732e-06\n",
      "Epoch 82/84\n",
      "24/23 - 10s - auc: 0.9881 - loss: 0.2251 - val_auc: 0.8643 - val_loss: 0.1897 - lr: 1.5159e-06\n",
      "Epoch 83/84\n",
      "24/23 - 10s - auc: 0.9883 - loss: 0.2219 - val_auc: 0.8626 - val_loss: 0.1892 - lr: 1.4643e-06\n",
      "Epoch 84/84\n",
      "24/23 - 10s - auc: 0.9855 - loss: 0.2339 - val_auc: 0.8613 - val_loss: 0.1887 - lr: 1.4179e-06\n",
      "Predicting OOF with TTA (AUC)...\n",
      "160/159 - 45s\n",
      "Predicting Test with TTA (AUC)...\n",
      "269/268 - 77s\n",
      "Predicting OOF with TTA (Loss)...\n",
      "160/159 - 46s\n",
      "Predicting Test with TTA (Loss)...\n",
      "269/268 - 78s\n",
      "#### FOLD 3 OOF AUC = 0.921, with TTA (Loss) = 0.933, with TTA (AUC) = 0.923, with TTA (Blend) = 0.935\n",
      "\n",
      "FOLD: 4\n",
      "TRAIN: [ 0  1  2  3  5  6  8  9 11 12 13 14] VALID: [ 4  7 10]\n",
      "Epoch 1/84\n",
      "24/23 - 36s - auc: 0.5819 - loss: 0.6943 - val_auc: 0.5734 - val_loss: 0.7070 - lr: 5.0000e-06\n",
      "Epoch 2/84\n",
      "24/23 - 12s - auc: 0.7352 - loss: 0.6372 - val_auc: 0.5634 - val_loss: 0.5538 - lr: 2.6000e-05\n",
      "Epoch 3/84\n",
      "24/23 - 15s - auc: 0.8369 - loss: 0.5387 - val_auc: 0.6021 - val_loss: 0.4131 - lr: 4.7000e-05\n",
      "Epoch 4/84\n",
      "24/23 - 15s - auc: 0.8734 - loss: 0.4787 - val_auc: 0.6524 - val_loss: 0.3372 - lr: 6.8000e-05\n",
      "Epoch 5/84\n",
      "24/23 - 15s - auc: 0.8942 - loss: 0.4417 - val_auc: 0.6975 - val_loss: 0.2576 - lr: 8.9000e-05\n",
      "Epoch 6/84\n",
      "24/23 - 15s - auc: 0.9214 - loss: 0.3971 - val_auc: 0.7810 - val_loss: 0.2507 - lr: 1.1000e-04\n",
      "Epoch 7/84\n",
      "24/23 - 15s - auc: 0.9334 - loss: 0.3738 - val_auc: 0.8173 - val_loss: 0.2166 - lr: 1.3100e-04\n",
      "Epoch 8/84\n",
      "24/23 - 15s - auc: 0.9414 - loss: 0.3586 - val_auc: 0.8449 - val_loss: 0.2147 - lr: 1.5200e-04\n",
      "Epoch 9/84\n",
      "24/23 - 12s - auc: 0.9193 - loss: 0.4018 - val_auc: 0.8578 - val_loss: 0.2191 - lr: 1.7300e-04\n",
      "Epoch 10/84\n",
      "24/23 - 12s - auc: 0.9168 - loss: 0.4058 - val_auc: 0.8828 - val_loss: 0.2223 - lr: 1.9400e-04\n",
      "Epoch 11/84\n",
      "24/23 - 12s - auc: 0.9227 - loss: 0.3968 - val_auc: 0.8942 - val_loss: 0.2666 - lr: 2.1500e-04\n",
      "Epoch 12/84\n",
      "24/23 - 12s - auc: 0.9291 - loss: 0.3846 - val_auc: 0.9001 - val_loss: 0.2223 - lr: 2.3600e-04\n",
      "Epoch 13/84\n",
      "24/23 - 10s - auc: 0.9325 - loss: 0.3775 - val_auc: 0.8857 - val_loss: 0.2227 - lr: 2.5700e-04\n",
      "Epoch 14/84\n",
      "24/23 - 10s - auc: 0.9389 - loss: 0.3648 - val_auc: 0.8866 - val_loss: 0.2404 - lr: 2.7800e-04\n",
      "Epoch 15/84\n",
      "24/23 - 12s - auc: 0.9485 - loss: 0.3441 - val_auc: 0.8999 - val_loss: 0.2001 - lr: 2.9900e-04\n",
      "Epoch 16/84\n",
      "24/23 - 10s - auc: 0.9583 - loss: 0.3191 - val_auc: 0.8818 - val_loss: 0.2339 - lr: 3.2000e-04\n",
      "Epoch 17/84\n",
      "24/23 - 12s - auc: 0.9662 - loss: 0.2992 - val_auc: 0.8956 - val_loss: 0.1876 - lr: 3.2000e-04\n",
      "Epoch 18/84\n",
      "24/23 - 13s - auc: 0.9712 - loss: 0.2844 - val_auc: 0.9047 - val_loss: 0.2144 - lr: 3.2000e-04\n",
      "Epoch 19/84\n",
      "24/23 - 10s - auc: 0.9495 - loss: 0.3403 - val_auc: 0.8984 - val_loss: 0.2288 - lr: 3.2000e-04\n",
      "Epoch 20/84\n",
      "24/23 - 10s - auc: 0.9526 - loss: 0.3359 - val_auc: 0.8941 - val_loss: 0.2860 - lr: 3.2000e-04\n",
      "Epoch 21/84\n",
      "24/23 - 10s - auc: 0.9554 - loss: 0.3288 - val_auc: 0.9037 - val_loss: 0.2513 - lr: 3.2000e-04\n",
      "Epoch 22/84\n",
      "24/23 - 10s - auc: 0.9642 - loss: 0.3075 - val_auc: 0.8933 - val_loss: 0.2275 - lr: 2.8810e-04\n",
      "Epoch 23/84\n",
      "24/23 - 10s - auc: 0.9634 - loss: 0.3070 - val_auc: 0.8999 - val_loss: 0.2349 - lr: 2.5939e-04\n",
      "Epoch 24/84\n",
      "24/23 - 10s - auc: 0.9681 - loss: 0.2955 - val_auc: 0.9036 - val_loss: 0.2266 - lr: 2.3355e-04\n",
      "Epoch 25/84\n",
      "24/23 - 10s - auc: 0.9734 - loss: 0.2811 - val_auc: 0.9031 - val_loss: 0.1893 - lr: 2.1030e-04\n",
      "Epoch 26/84\n",
      "24/23 - 10s - auc: 0.9770 - loss: 0.2668 - val_auc: 0.8937 - val_loss: 0.1885 - lr: 1.8937e-04\n",
      "Epoch 27/84\n",
      "24/23 - 10s - auc: 0.9838 - loss: 0.2425 - val_auc: 0.8874 - val_loss: 0.1890 - lr: 1.7053e-04\n",
      "Epoch 28/84\n",
      "24/23 - 10s - auc: 0.9835 - loss: 0.2429 - val_auc: 0.8888 - val_loss: 0.1877 - lr: 1.5358e-04\n",
      "Epoch 29/84\n",
      "24/23 - 10s - auc: 0.9772 - loss: 0.2666 - val_auc: 0.8897 - val_loss: 0.2072 - lr: 1.3832e-04\n",
      "Epoch 30/84\n",
      "24/23 - 10s - auc: 0.9765 - loss: 0.2688 - val_auc: 0.8842 - val_loss: 0.2040 - lr: 1.2459e-04\n",
      "Epoch 31/84\n",
      "24/23 - 10s - auc: 0.9764 - loss: 0.2677 - val_auc: 0.8690 - val_loss: 0.1994 - lr: 1.1223e-04\n",
      "Epoch 32/84\n",
      "24/23 - 10s - auc: 0.9800 - loss: 0.2571 - val_auc: 0.8697 - val_loss: 0.1998 - lr: 1.0111e-04\n",
      "Epoch 33/84\n",
      "24/23 - 10s - auc: 0.9797 - loss: 0.2572 - val_auc: 0.8998 - val_loss: 0.2023 - lr: 9.1095e-05\n",
      "Epoch 34/84\n",
      "24/23 - 10s - auc: 0.9826 - loss: 0.2478 - val_auc: 0.8874 - val_loss: 0.1956 - lr: 8.2086e-05\n",
      "Epoch 35/84\n",
      "24/23 - 10s - auc: 0.9834 - loss: 0.2412 - val_auc: 0.8868 - val_loss: 0.1910 - lr: 7.3977e-05\n",
      "Epoch 36/84\n",
      "24/23 - 10s - auc: 0.9880 - loss: 0.2245 - val_auc: 0.8874 - val_loss: 0.1928 - lr: 6.6679e-05\n",
      "Epoch 37/84\n",
      "24/23 - 10s - auc: 0.9911 - loss: 0.2093 - val_auc: 0.8798 - val_loss: 0.1957 - lr: 6.0111e-05\n",
      "Epoch 38/84\n",
      "24/23 - 10s - auc: 0.9886 - loss: 0.2211 - val_auc: 0.8846 - val_loss: 0.1893 - lr: 5.4200e-05\n",
      "Epoch 39/84\n",
      "24/23 - 10s - auc: 0.9830 - loss: 0.2435 - val_auc: 0.8802 - val_loss: 0.1986 - lr: 4.8880e-05\n",
      "Epoch 40/84\n",
      "24/23 - 10s - auc: 0.9835 - loss: 0.2438 - val_auc: 0.8842 - val_loss: 0.1943 - lr: 4.4092e-05\n",
      "Epoch 41/84\n",
      "24/23 - 10s - auc: 0.9843 - loss: 0.2419 - val_auc: 0.8864 - val_loss: 0.1964 - lr: 3.9783e-05\n",
      "Epoch 42/84\n",
      "24/23 - 10s - auc: 0.9853 - loss: 0.2350 - val_auc: 0.8826 - val_loss: 0.1941 - lr: 3.5905e-05\n",
      "Epoch 43/84\n",
      "24/23 - 10s - auc: 0.9876 - loss: 0.2272 - val_auc: 0.8848 - val_loss: 0.1994 - lr: 3.2414e-05\n",
      "Epoch 44/84\n",
      "24/23 - 14s - auc: 0.9857 - loss: 0.2336 - val_auc: 0.8849 - val_loss: 0.1979 - lr: 2.9273e-05\n",
      "Epoch 45/84\n",
      "24/23 - 10s - auc: 0.9866 - loss: 0.2297 - val_auc: 0.8911 - val_loss: 0.1964 - lr: 2.6445e-05\n",
      "Epoch 46/84\n",
      "24/23 - 10s - auc: 0.9916 - loss: 0.2076 - val_auc: 0.8941 - val_loss: 0.1979 - lr: 2.3901e-05\n",
      "Epoch 47/84\n",
      "24/23 - 10s - auc: 0.9932 - loss: 0.1981 - val_auc: 0.8915 - val_loss: 0.1948 - lr: 2.1611e-05\n",
      "Epoch 48/84\n",
      "24/23 - 10s - auc: 0.9911 - loss: 0.2086 - val_auc: 0.8854 - val_loss: 0.1958 - lr: 1.9550e-05\n",
      "Epoch 49/84\n",
      "24/23 - 10s - auc: 0.9856 - loss: 0.2342 - val_auc: 0.8698 - val_loss: 0.1899 - lr: 1.7695e-05\n",
      "Epoch 50/84\n",
      "24/23 - 10s - auc: 0.9838 - loss: 0.2415 - val_auc: 0.8730 - val_loss: 0.1879 - lr: 1.6025e-05\n",
      "Epoch 51/84\n",
      "24/23 - 10s - auc: 0.9881 - loss: 0.2237 - val_auc: 0.8777 - val_loss: 0.1909 - lr: 1.4523e-05\n",
      "Epoch 52/84\n",
      "24/23 - 10s - auc: 0.9861 - loss: 0.2324 - val_auc: 0.8807 - val_loss: 0.1918 - lr: 1.3171e-05\n",
      "Epoch 53/84\n",
      "24/23 - 10s - auc: 0.9887 - loss: 0.2217 - val_auc: 0.8821 - val_loss: 0.1929 - lr: 1.1953e-05\n",
      "Epoch 54/84\n",
      "24/23 - 10s - auc: 0.9904 - loss: 0.2153 - val_auc: 0.8784 - val_loss: 0.1935 - lr: 1.0858e-05\n",
      "Epoch 55/84\n",
      "24/23 - 10s - auc: 0.9900 - loss: 0.2143 - val_auc: 0.8788 - val_loss: 0.1959 - lr: 9.8723e-06\n",
      "Epoch 56/84\n",
      "24/23 - 10s - auc: 0.9926 - loss: 0.1999 - val_auc: 0.8817 - val_loss: 0.1967 - lr: 8.9851e-06\n",
      "Epoch 57/84\n",
      "24/23 - 10s - auc: 0.9931 - loss: 0.1985 - val_auc: 0.8807 - val_loss: 0.1950 - lr: 8.1866e-06\n",
      "Epoch 58/84\n",
      "24/23 - 10s - auc: 0.9903 - loss: 0.2130 - val_auc: 0.8752 - val_loss: 0.1928 - lr: 7.4679e-06\n",
      "Epoch 59/84\n",
      "24/23 - 10s - auc: 0.9862 - loss: 0.2312 - val_auc: 0.8706 - val_loss: 0.1903 - lr: 6.8211e-06\n",
      "Epoch 60/84\n",
      "24/23 - 10s - auc: 0.9871 - loss: 0.2276 - val_auc: 0.8735 - val_loss: 0.1894 - lr: 6.2390e-06\n",
      "Epoch 61/84\n",
      "24/23 - 10s - auc: 0.9869 - loss: 0.2301 - val_auc: 0.8749 - val_loss: 0.1897 - lr: 5.7151e-06\n",
      "Epoch 62/84\n",
      "24/23 - 10s - auc: 0.9879 - loss: 0.2246 - val_auc: 0.8746 - val_loss: 0.1901 - lr: 5.2436e-06\n",
      "Epoch 63/84\n",
      "24/23 - 10s - auc: 0.9888 - loss: 0.2201 - val_auc: 0.8775 - val_loss: 0.1916 - lr: 4.8192e-06\n",
      "Epoch 64/84\n",
      "24/23 - 10s - auc: 0.9905 - loss: 0.2130 - val_auc: 0.8807 - val_loss: 0.1931 - lr: 4.4373e-06\n",
      "Epoch 65/84\n",
      "24/23 - 10s - auc: 0.9904 - loss: 0.2142 - val_auc: 0.8814 - val_loss: 0.1941 - lr: 4.0936e-06\n",
      "Epoch 66/84\n",
      "24/23 - 10s - auc: 0.9933 - loss: 0.2001 - val_auc: 0.8831 - val_loss: 0.1956 - lr: 3.7842e-06\n",
      "Epoch 67/84\n",
      "24/23 - 10s - auc: 0.9938 - loss: 0.1966 - val_auc: 0.8798 - val_loss: 0.1962 - lr: 3.5058e-06\n",
      "Epoch 68/84\n",
      "24/23 - 10s - auc: 0.9896 - loss: 0.2151 - val_auc: 0.8786 - val_loss: 0.1952 - lr: 3.2552e-06\n",
      "Epoch 69/84\n",
      "24/23 - 10s - auc: 0.9859 - loss: 0.2307 - val_auc: 0.8796 - val_loss: 0.1934 - lr: 3.0297e-06\n",
      "Epoch 70/84\n",
      "24/23 - 10s - auc: 0.9857 - loss: 0.2335 - val_auc: 0.8742 - val_loss: 0.1921 - lr: 2.8267e-06\n",
      "Epoch 71/84\n",
      "24/23 - 10s - auc: 0.9878 - loss: 0.2245 - val_auc: 0.8746 - val_loss: 0.1914 - lr: 2.6441e-06\n",
      "Epoch 72/84\n",
      "24/23 - 10s - auc: 0.9886 - loss: 0.2213 - val_auc: 0.8772 - val_loss: 0.1922 - lr: 2.4796e-06\n",
      "Epoch 73/84\n",
      "24/23 - 10s - auc: 0.9883 - loss: 0.2207 - val_auc: 0.8787 - val_loss: 0.1915 - lr: 2.3317e-06\n",
      "Epoch 74/84\n",
      "24/23 - 10s - auc: 0.9902 - loss: 0.2136 - val_auc: 0.8787 - val_loss: 0.1916 - lr: 2.1985e-06\n",
      "Epoch 75/84\n",
      "24/23 - 10s - auc: 0.9919 - loss: 0.2056 - val_auc: 0.8782 - val_loss: 0.1924 - lr: 2.0787e-06\n",
      "Epoch 76/84\n",
      "24/23 - 10s - auc: 0.9938 - loss: 0.1987 - val_auc: 0.8799 - val_loss: 0.1931 - lr: 1.9708e-06\n",
      "Epoch 77/84\n",
      "24/23 - 10s - auc: 0.9940 - loss: 0.1943 - val_auc: 0.8773 - val_loss: 0.1944 - lr: 1.8737e-06\n",
      "Epoch 78/84\n",
      "24/23 - 10s - auc: 0.9888 - loss: 0.2190 - val_auc: 0.8776 - val_loss: 0.1944 - lr: 1.7863e-06\n",
      "Epoch 79/84\n",
      "24/23 - 10s - auc: 0.9874 - loss: 0.2264 - val_auc: 0.8813 - val_loss: 0.1935 - lr: 1.7077e-06\n",
      "Epoch 80/84\n",
      "24/23 - 10s - auc: 0.9876 - loss: 0.2269 - val_auc: 0.8801 - val_loss: 0.1928 - lr: 1.6369e-06\n",
      "Epoch 81/84\n",
      "24/23 - 10s - auc: 0.9886 - loss: 0.2195 - val_auc: 0.8784 - val_loss: 0.1919 - lr: 1.5732e-06\n",
      "Epoch 82/84\n",
      "24/23 - 10s - auc: 0.9900 - loss: 0.2161 - val_auc: 0.8788 - val_loss: 0.1918 - lr: 1.5159e-06\n",
      "Epoch 83/84\n",
      "24/23 - 10s - auc: 0.9889 - loss: 0.2192 - val_auc: 0.8770 - val_loss: 0.1915 - lr: 1.4643e-06\n",
      "Epoch 84/84\n",
      "24/23 - 10s - auc: 0.9884 - loss: 0.2214 - val_auc: 0.8776 - val_loss: 0.1917 - lr: 1.4179e-06\n",
      "Predicting OOF with TTA (AUC)...\n",
      "160/159 - 45s\n",
      "Predicting Test with TTA (AUC)...\n",
      "269/268 - 77s\n",
      "Predicting OOF with TTA (Loss)...\n",
      "160/159 - 46s\n",
      "Predicting Test with TTA (Loss)...\n",
      "269/268 - 78s\n",
      "#### FOLD 4 OOF AUC = 0.905, with TTA (Loss) = 0.919, with TTA (AUC) = 0.919, with TTA (Blend) = 0.922\n",
      "\n",
      "FOLD: 5\n",
      "TRAIN: [ 0  1  2  4  5  7  8  9 10 11 13 14] VALID: [ 3  6 12]\n",
      "Epoch 1/84\n",
      "24/23 - 35s - auc: 0.5417 - loss: 0.6919 - val_auc: 0.4898 - val_loss: 0.5729 - lr: 5.0000e-06\n",
      "Epoch 2/84\n",
      "24/23 - 15s - auc: 0.7391 - loss: 0.6294 - val_auc: 0.5997 - val_loss: 0.4580 - lr: 2.6000e-05\n",
      "Epoch 3/84\n",
      "24/23 - 15s - auc: 0.8397 - loss: 0.5285 - val_auc: 0.6623 - val_loss: 0.3112 - lr: 4.7000e-05\n",
      "Epoch 4/84\n",
      "24/23 - 15s - auc: 0.8651 - loss: 0.4828 - val_auc: 0.7154 - val_loss: 0.2677 - lr: 6.8000e-05\n",
      "Epoch 5/84\n",
      "24/23 - 15s - auc: 0.8684 - loss: 0.4748 - val_auc: 0.7563 - val_loss: 0.2641 - lr: 8.9000e-05\n",
      "Epoch 6/84\n",
      "24/23 - 15s - auc: 0.9104 - loss: 0.4188 - val_auc: 0.7922 - val_loss: 0.2308 - lr: 1.1000e-04\n",
      "Epoch 7/84\n",
      "24/23 - 15s - auc: 0.9267 - loss: 0.3884 - val_auc: 0.8372 - val_loss: 0.2283 - lr: 1.3100e-04\n",
      "Epoch 8/84\n",
      "24/23 - 15s - auc: 0.9403 - loss: 0.3615 - val_auc: 0.8680 - val_loss: 0.1959 - lr: 1.5200e-04\n",
      "Epoch 9/84\n",
      "24/23 - 12s - auc: 0.9382 - loss: 0.3657 - val_auc: 0.8769 - val_loss: 0.2294 - lr: 1.7300e-04\n",
      "Epoch 10/84\n",
      "24/23 - 13s - auc: 0.9483 - loss: 0.3444 - val_auc: 0.8849 - val_loss: 0.2163 - lr: 1.9400e-04\n",
      "Epoch 11/84\n",
      "24/23 - 10s - auc: 0.9321 - loss: 0.3789 - val_auc: 0.8832 - val_loss: 0.2059 - lr: 2.1500e-04\n",
      "Epoch 12/84\n",
      "24/23 - 10s - auc: 0.9294 - loss: 0.3842 - val_auc: 0.8837 - val_loss: 0.2692 - lr: 2.3600e-04\n",
      "Epoch 13/84\n",
      "24/23 - 12s - auc: 0.9393 - loss: 0.3660 - val_auc: 0.8904 - val_loss: 0.2532 - lr: 2.5700e-04\n",
      "Epoch 14/84\n",
      "24/23 - 10s - auc: 0.9395 - loss: 0.3632 - val_auc: 0.8879 - val_loss: 0.2476 - lr: 2.7800e-04\n",
      "Epoch 15/84\n",
      "24/23 - 12s - auc: 0.9315 - loss: 0.3795 - val_auc: 0.8942 - val_loss: 0.2503 - lr: 2.9900e-04\n",
      "Epoch 16/84\n",
      "24/23 - 12s - auc: 0.9514 - loss: 0.3378 - val_auc: 0.8995 - val_loss: 0.2455 - lr: 3.2000e-04\n",
      "Epoch 17/84\n",
      "24/23 - 10s - auc: 0.9644 - loss: 0.3061 - val_auc: 0.8861 - val_loss: 0.2075 - lr: 3.2000e-04\n",
      "Epoch 18/84\n",
      "24/23 - 10s - auc: 0.9662 - loss: 0.2996 - val_auc: 0.8777 - val_loss: 0.1959 - lr: 3.2000e-04\n",
      "Epoch 19/84\n",
      "24/23 - 10s - auc: 0.9683 - loss: 0.2941 - val_auc: 0.8834 - val_loss: 0.2053 - lr: 3.2000e-04\n",
      "Epoch 20/84\n",
      "24/23 - 12s - auc: 0.9704 - loss: 0.2870 - val_auc: 0.8903 - val_loss: 0.1901 - lr: 3.2000e-04\n",
      "Epoch 21/84\n",
      "24/23 - 10s - auc: 0.9630 - loss: 0.3092 - val_auc: 0.8784 - val_loss: 0.2136 - lr: 3.2000e-04\n",
      "Epoch 22/84\n",
      "24/23 - 10s - auc: 0.9596 - loss: 0.3174 - val_auc: 0.8900 - val_loss: 0.2218 - lr: 2.8810e-04\n",
      "Epoch 23/84\n",
      "24/23 - 10s - auc: 0.9643 - loss: 0.3061 - val_auc: 0.8792 - val_loss: 0.2174 - lr: 2.5939e-04\n",
      "Epoch 24/84\n",
      "24/23 - 10s - auc: 0.9660 - loss: 0.3007 - val_auc: 0.8821 - val_loss: 0.2429 - lr: 2.3355e-04\n",
      "Epoch 25/84\n",
      "24/23 - 10s - auc: 0.9661 - loss: 0.2996 - val_auc: 0.8918 - val_loss: 0.2289 - lr: 2.1030e-04\n",
      "Epoch 26/84\n",
      "24/23 - 10s - auc: 0.9737 - loss: 0.2775 - val_auc: 0.8863 - val_loss: 0.2098 - lr: 1.8937e-04\n",
      "Epoch 27/84\n",
      "24/23 - 10s - auc: 0.9803 - loss: 0.2554 - val_auc: 0.8919 - val_loss: 0.1955 - lr: 1.7053e-04\n",
      "Epoch 28/84\n",
      "24/23 - 10s - auc: 0.9822 - loss: 0.2472 - val_auc: 0.8950 - val_loss: 0.1999 - lr: 1.5358e-04\n",
      "Epoch 29/84\n",
      "24/23 - 12s - auc: 0.9840 - loss: 0.2419 - val_auc: 0.9030 - val_loss: 0.1959 - lr: 1.3832e-04\n",
      "Epoch 30/84\n",
      "24/23 - 10s - auc: 0.9848 - loss: 0.2370 - val_auc: 0.8826 - val_loss: 0.1910 - lr: 1.2459e-04\n",
      "Epoch 31/84\n",
      "24/23 - 10s - auc: 0.9797 - loss: 0.2573 - val_auc: 0.9008 - val_loss: 0.2007 - lr: 1.1223e-04\n",
      "Epoch 32/84\n",
      "24/23 - 10s - auc: 0.9791 - loss: 0.2586 - val_auc: 0.8906 - val_loss: 0.1956 - lr: 1.0111e-04\n",
      "Epoch 33/84\n",
      "24/23 - 12s - auc: 0.9807 - loss: 0.2526 - val_auc: 0.8754 - val_loss: 0.1871 - lr: 9.1095e-05\n",
      "Epoch 34/84\n",
      "24/23 - 10s - auc: 0.9791 - loss: 0.2592 - val_auc: 0.8807 - val_loss: 0.2049 - lr: 8.2086e-05\n",
      "Epoch 35/84\n",
      "24/23 - 10s - auc: 0.9800 - loss: 0.2548 - val_auc: 0.8668 - val_loss: 0.1940 - lr: 7.3977e-05\n",
      "Epoch 36/84\n",
      "24/23 - 10s - auc: 0.9843 - loss: 0.2384 - val_auc: 0.8857 - val_loss: 0.2007 - lr: 6.6679e-05\n",
      "Epoch 37/84\n",
      "24/23 - 10s - auc: 0.9884 - loss: 0.2226 - val_auc: 0.8883 - val_loss: 0.1941 - lr: 6.0111e-05\n",
      "Epoch 38/84\n",
      "24/23 - 10s - auc: 0.9901 - loss: 0.2134 - val_auc: 0.8825 - val_loss: 0.1879 - lr: 5.4200e-05\n",
      "Epoch 39/84\n",
      "24/23 - 10s - auc: 0.9900 - loss: 0.2147 - val_auc: 0.8732 - val_loss: 0.1924 - lr: 4.8880e-05\n",
      "Epoch 40/84\n",
      "24/23 - 12s - auc: 0.9869 - loss: 0.2266 - val_auc: 0.8650 - val_loss: 0.1862 - lr: 4.4092e-05\n",
      "Epoch 41/84\n",
      "24/23 - 10s - auc: 0.9842 - loss: 0.2401 - val_auc: 0.8707 - val_loss: 0.1884 - lr: 3.9783e-05\n",
      "Epoch 42/84\n",
      "24/23 - 10s - auc: 0.9860 - loss: 0.2322 - val_auc: 0.8608 - val_loss: 0.1889 - lr: 3.5905e-05\n",
      "Epoch 43/84\n",
      "24/23 - 10s - auc: 0.9851 - loss: 0.2368 - val_auc: 0.8591 - val_loss: 0.1919 - lr: 3.2414e-05\n",
      "Epoch 44/84\n",
      "24/23 - 10s - auc: 0.9823 - loss: 0.2484 - val_auc: 0.8636 - val_loss: 0.1928 - lr: 2.9273e-05\n",
      "Epoch 45/84\n",
      "24/23 - 10s - auc: 0.9833 - loss: 0.2427 - val_auc: 0.8671 - val_loss: 0.1912 - lr: 2.6445e-05\n",
      "Epoch 46/84\n",
      "24/23 - 10s - auc: 0.9886 - loss: 0.2224 - val_auc: 0.8693 - val_loss: 0.1910 - lr: 2.3901e-05\n",
      "Epoch 47/84\n",
      "24/23 - 10s - auc: 0.9923 - loss: 0.2045 - val_auc: 0.8664 - val_loss: 0.1899 - lr: 2.1611e-05\n",
      "Epoch 48/84\n",
      "24/23 - 10s - auc: 0.9917 - loss: 0.2071 - val_auc: 0.8627 - val_loss: 0.1872 - lr: 1.9550e-05\n",
      "Epoch 49/84\n",
      "24/23 - 10s - auc: 0.9922 - loss: 0.2038 - val_auc: 0.8628 - val_loss: 0.1865 - lr: 1.7695e-05\n",
      "Epoch 50/84\n",
      "24/23 - 12s - auc: 0.9918 - loss: 0.2057 - val_auc: 0.8590 - val_loss: 0.1846 - lr: 1.6025e-05\n",
      "Epoch 51/84\n",
      "24/23 - 10s - auc: 0.9875 - loss: 0.2255 - val_auc: 0.8610 - val_loss: 0.1861 - lr: 1.4523e-05\n",
      "Epoch 52/84\n",
      "24/23 - 10s - auc: 0.9860 - loss: 0.2302 - val_auc: 0.8643 - val_loss: 0.1869 - lr: 1.3171e-05\n",
      "Epoch 53/84\n",
      "24/23 - 10s - auc: 0.9859 - loss: 0.2295 - val_auc: 0.8628 - val_loss: 0.1894 - lr: 1.1953e-05\n",
      "Epoch 54/84\n",
      "24/23 - 10s - auc: 0.9875 - loss: 0.2250 - val_auc: 0.8666 - val_loss: 0.1915 - lr: 1.0858e-05\n",
      "Epoch 55/84\n",
      "24/23 - 10s - auc: 0.9870 - loss: 0.2287 - val_auc: 0.8651 - val_loss: 0.1905 - lr: 9.8723e-06\n",
      "Epoch 56/84\n",
      "24/23 - 10s - auc: 0.9904 - loss: 0.2130 - val_auc: 0.8686 - val_loss: 0.1904 - lr: 8.9851e-06\n",
      "Epoch 57/84\n",
      "24/23 - 10s - auc: 0.9932 - loss: 0.1989 - val_auc: 0.8736 - val_loss: 0.1897 - lr: 8.1866e-06\n",
      "Epoch 58/84\n",
      "24/23 - 10s - auc: 0.9918 - loss: 0.2072 - val_auc: 0.8711 - val_loss: 0.1882 - lr: 7.4679e-06\n",
      "Epoch 59/84\n",
      "24/23 - 10s - auc: 0.9936 - loss: 0.1953 - val_auc: 0.8710 - val_loss: 0.1884 - lr: 6.8211e-06\n",
      "Epoch 60/84\n",
      "24/23 - 10s - auc: 0.9908 - loss: 0.2107 - val_auc: 0.8708 - val_loss: 0.1877 - lr: 6.2390e-06\n",
      "Epoch 61/84\n",
      "24/23 - 10s - auc: 0.9875 - loss: 0.2245 - val_auc: 0.8682 - val_loss: 0.1865 - lr: 5.7151e-06\n",
      "Epoch 62/84\n",
      "24/23 - 10s - auc: 0.9861 - loss: 0.2324 - val_auc: 0.8600 - val_loss: 0.1849 - lr: 5.2436e-06\n",
      "Epoch 63/84\n",
      "24/23 - 10s - auc: 0.9893 - loss: 0.2176 - val_auc: 0.8638 - val_loss: 0.1861 - lr: 4.8192e-06\n",
      "Epoch 64/84\n",
      "24/23 - 10s - auc: 0.9874 - loss: 0.2253 - val_auc: 0.8585 - val_loss: 0.1868 - lr: 4.4373e-06\n",
      "Epoch 65/84\n",
      "24/23 - 10s - auc: 0.9891 - loss: 0.2180 - val_auc: 0.8612 - val_loss: 0.1872 - lr: 4.0936e-06\n",
      "Epoch 66/84\n",
      "24/23 - 10s - auc: 0.9906 - loss: 0.2098 - val_auc: 0.8642 - val_loss: 0.1875 - lr: 3.7842e-06\n",
      "Epoch 67/84\n",
      "24/23 - 10s - auc: 0.9918 - loss: 0.2053 - val_auc: 0.8702 - val_loss: 0.1889 - lr: 3.5058e-06\n",
      "Epoch 68/84\n",
      "24/23 - 10s - auc: 0.9929 - loss: 0.2010 - val_auc: 0.8699 - val_loss: 0.1889 - lr: 3.2552e-06\n",
      "Epoch 69/84\n",
      "24/23 - 10s - auc: 0.9929 - loss: 0.1994 - val_auc: 0.8694 - val_loss: 0.1889 - lr: 3.0297e-06\n",
      "Epoch 70/84\n",
      "24/23 - 10s - auc: 0.9905 - loss: 0.2111 - val_auc: 0.8723 - val_loss: 0.1884 - lr: 2.8267e-06\n",
      "Epoch 71/84\n",
      "24/23 - 10s - auc: 0.9882 - loss: 0.2223 - val_auc: 0.8705 - val_loss: 0.1872 - lr: 2.6441e-06\n",
      "Epoch 72/84\n",
      "24/23 - 10s - auc: 0.9874 - loss: 0.2257 - val_auc: 0.8669 - val_loss: 0.1874 - lr: 2.4796e-06\n",
      "Epoch 73/84\n",
      "24/23 - 10s - auc: 0.9883 - loss: 0.2216 - val_auc: 0.8643 - val_loss: 0.1873 - lr: 2.3317e-06\n",
      "Epoch 74/84\n",
      "24/23 - 10s - auc: 0.9870 - loss: 0.2295 - val_auc: 0.8589 - val_loss: 0.1866 - lr: 2.1985e-06\n",
      "Epoch 75/84\n",
      "24/23 - 10s - auc: 0.9902 - loss: 0.2133 - val_auc: 0.8563 - val_loss: 0.1866 - lr: 2.0787e-06\n",
      "Epoch 76/84\n",
      "24/23 - 10s - auc: 0.9911 - loss: 0.2105 - val_auc: 0.8624 - val_loss: 0.1870 - lr: 1.9708e-06\n",
      "Epoch 77/84\n",
      "24/23 - 10s - auc: 0.9929 - loss: 0.2010 - val_auc: 0.8657 - val_loss: 0.1876 - lr: 1.8737e-06\n",
      "Epoch 78/84\n",
      "24/23 - 10s - auc: 0.9927 - loss: 0.1993 - val_auc: 0.8644 - val_loss: 0.1880 - lr: 1.7863e-06\n",
      "Epoch 79/84\n",
      "24/23 - 10s - auc: 0.9931 - loss: 0.1998 - val_auc: 0.8671 - val_loss: 0.1883 - lr: 1.7077e-06\n",
      "Epoch 80/84\n",
      "24/23 - 10s - auc: 0.9895 - loss: 0.2144 - val_auc: 0.8656 - val_loss: 0.1881 - lr: 1.6369e-06\n",
      "Epoch 81/84\n",
      "24/23 - 10s - auc: 0.9875 - loss: 0.2271 - val_auc: 0.8683 - val_loss: 0.1876 - lr: 1.5732e-06\n",
      "Epoch 82/84\n",
      "24/23 - 10s - auc: 0.9874 - loss: 0.2254 - val_auc: 0.8627 - val_loss: 0.1869 - lr: 1.5159e-06\n",
      "Epoch 83/84\n",
      "24/23 - 10s - auc: 0.9896 - loss: 0.2176 - val_auc: 0.8613 - val_loss: 0.1868 - lr: 1.4643e-06\n",
      "Epoch 84/84\n",
      "24/23 - 10s - auc: 0.9863 - loss: 0.2312 - val_auc: 0.8622 - val_loss: 0.1866 - lr: 1.4179e-06\n",
      "Predicting OOF with TTA (AUC)...\n",
      "161/160 - 45s\n",
      "Predicting Test with TTA (AUC)...\n",
      "269/268 - 77s\n",
      "Predicting OOF with TTA (Loss)...\n",
      "161/160 - 47s\n",
      "Predicting Test with TTA (Loss)...\n",
      "269/268 - 78s\n",
      "#### FOLD 5 OOF AUC = 0.903, with TTA (Loss) = 0.902, with TTA (AUC) = 0.916, with TTA (Blend) = 0.913\n"
     ]
    }
   ],
   "source": [
    "skf = KFold(n_splits=config['N_USED_FOLDS'], shuffle=True, random_state=SEED)\n",
    "oof_pred = []; oof_tar = []; oof_val = []; oof_names = []; oof_folds = []; history_list = []; oof_pred_last = []\n",
    "preds = np.zeros((len(test), 1))\n",
    "preds_last = np.zeros((len(test), 1))\n",
    "\n",
    "for fold,(idxT, idxV) in enumerate(skf.split(np.arange(15))):\n",
    "    if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    print(f'\\nFOLD: {fold+1}')\n",
    "    print(f'TRAIN: {idxT} VALID: {idxV}')\n",
    "\n",
    "    # CREATE TRAIN AND VALIDATION SUBSETS\n",
    "    TRAINING_FILENAMES = tf.io.gfile.glob([GCS_PATH + '/train%.2i*.tfrec' % x for x in idxT])\n",
    "    # Add external data\n",
    "    # TRAINING_FILENAMES += tf.io.gfile.glob([GCS_2019_PATH + '/train%.2i*.tfrec' % (x*2+1) for x in idxT]) # 2019 data\n",
    "    TRAINING_FILENAMES += tf.io.gfile.glob([GCS_2019_PATH + '/train%.2i*.tfrec' % (x*2) for x in idxT]) # 2018 data\n",
    "    # Add extra malignant data\n",
    "    TRAINING_MALIG_FILENAMES = tf.io.gfile.glob([GCS_MALIGNANT_PATH + '/train%.2i*.tfrec' % x for x in idxT]) # 2020 data\n",
    "    TRAINING_MALIG_FILENAMES += tf.io.gfile.glob([GCS_MALIGNANT_PATH + '/train%.2i*.tfrec' % ((x*2+1)+30) for x in idxT]) # 2019 data\n",
    "    TRAINING_MALIG_FILENAMES += tf.io.gfile.glob([GCS_MALIGNANT_PATH + '/train%.2i*.tfrec' % ((x*2)+30) for x in idxT]) # 2018 data\n",
    "    TRAINING_MALIG_FILENAMES += tf.io.gfile.glob([GCS_MALIGNANT_PATH + '/train%.2i*.tfrec' % (x+15) for x in idxT]) # new data\n",
    "\n",
    "    np.random.shuffle(TRAINING_FILENAMES)\n",
    "    np.random.shuffle(TRAINING_MALIG_FILENAMES)\n",
    "    ds_regular = get_dataset_sampling(TRAINING_FILENAMES, augment=data_augment, shuffle=True, repeat=True,\n",
    "                                      dim=config['HEIGHT'], batch_size=config['BATCH_SIZE'])\n",
    "    ds_malig = get_dataset_sampling(TRAINING_MALIG_FILENAMES, augment=data_augment, shuffle=True, repeat=True,\n",
    "                                    dim=config['HEIGHT'], batch_size=config['BATCH_SIZE'])\n",
    "    # Resampled TF Dataset\n",
    "    resampled_ds = tf.data.experimental.sample_from_datasets([ds_regular, ds_malig], weights=[0.6, 0.4])\n",
    "    resampled_ds = resampled_ds.batch(config['BATCH_SIZE'] * REPLICAS).prefetch(AUTO)\n",
    "\n",
    "    files_valid = tf.io.gfile.glob([GCS_PATH + '/train%.2i*.tfrec'%x for x in idxV])\n",
    "    TEST_FILENAMES = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')))\n",
    "    ct_valid = count_data_items(files_valid)\n",
    "    ct_test = count_data_items(TEST_FILENAMES)\n",
    "    VALID_STEPS = config['TTA_STEPS'] * ct_valid/config['BATCH_SIZE']/4/REPLICAS\n",
    "    TEST_STEPS = config['TTA_STEPS'] * ct_test/config['BATCH_SIZE']/4/REPLICAS\n",
    "    \n",
    "    # MODEL\n",
    "    K.clear_session()\n",
    "    with strategy.scope():\n",
    "        model = model_fn((config['HEIGHT'], config['WIDTH'], config['CHANNELS']))\n",
    "\n",
    "    model_path_best_auc = f'model_{fold}_auc.h5'\n",
    "    model_path_best_loss = f'model_{fold}_loss.h5'\n",
    "    # model_path_last = f'model_{fold}_last.h5'\n",
    "    checkpoint_auc = ModelCheckpoint(model_path_best_auc, monitor='val_auc', mode='max', save_best_only=True,\n",
    "                                     save_weights_only=True, verbose=0)\n",
    "    checkpoint_loss = ModelCheckpoint(model_path_best_loss, monitor='val_loss', mode='min', save_best_only=True,\n",
    "                                      save_weights_only=True, verbose=0)\n",
    "   \n",
    "    # TRAIN\n",
    "    history = model.fit(resampled_ds, \n",
    "                        validation_data=get_dataset(files_valid, augment=None, shuffle=False,\n",
    "                                                    repeat=False, dim=config['HEIGHT']), \n",
    "                        steps_per_epoch=((count_data_items(TRAINING_FILENAMES) / 0.6)/config['BATCH_SIZE']//REPLICAS / 10), \n",
    "                        callbacks=[checkpoint_auc, checkpoint_loss, get_lr_callback()], \n",
    "                        epochs=config['EPOCHS'] * 7, \n",
    "                        verbose=2).history\n",
    "    \n",
    "    history_list.append(history)\n",
    "    # Save last model weights\n",
    "    # model.save_weights(model_path_last)\n",
    "\n",
    "    # GET OOF TARGETS AND NAMES\n",
    "    ds_valid = get_dataset(files_valid, augment=None, repeat=False, dim=config['HEIGHT'],\n",
    "                           labeled=True, return_image_names=True)\n",
    "    oof_tar.append(np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]))\n",
    "    oof_folds.append(np.ones_like(oof_tar[-1], dtype='int8')*fold)\n",
    "    ds = get_dataset(files_valid, augment=None, repeat=False, dim=config['HEIGHT'],\n",
    "                     labeled=False, return_image_names=True)\n",
    "    oof_names.append(np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())]))\n",
    "\n",
    "    # Load best model weights (AUC)\n",
    "    model.load_weights(model_path_best_auc)\n",
    "    \n",
    "    # PREDICT OOF USING TTA (AUC)\n",
    "    print('Predicting OOF with TTA (AUC)...')\n",
    "    ds_valid = get_dataset(files_valid, labeled=False, return_image_names=False, augment=data_augment_tta,\n",
    "                           repeat=True, shuffle=False, dim=config['HEIGHT'], batch_size=config['BATCH_SIZE']*4)\n",
    "    pred = model.predict(ds_valid, steps=VALID_STEPS, verbose=2)[:config['TTA_STEPS']*ct_valid,]\n",
    "    oof_pred_last.append(np.mean(pred.reshape((ct_valid, config['TTA_STEPS']), order='F'),axis=1))\n",
    "\n",
    "    # PREDICT TEST USING TTA (AUC)\n",
    "    print('Predicting Test with TTA (AUC)...')\n",
    "    ds_test = get_dataset(TEST_FILENAMES, labeled=False, return_image_names=False, augment=data_augment_tta,\n",
    "                          repeat=True, shuffle=False, dim=config['HEIGHT'], batch_size=config['BATCH_SIZE']*4)\n",
    "    pred = model.predict(ds_test, steps=TEST_STEPS, verbose=2)[:config['TTA_STEPS']*ct_test,]\n",
    "    preds_last[:,0] += np.mean(pred.reshape((ct_test, config['TTA_STEPS']), order='F'), axis=1) / config['N_USED_FOLDS']\n",
    "    \n",
    "\n",
    "    # Load best model weights (Loss)\n",
    "    model.load_weights(model_path_best_loss)\n",
    "    \n",
    "    # PREDICT OOF USING TTA (Loss)\n",
    "    print('Predicting OOF with TTA (Loss)...')\n",
    "    pred = model.predict(ds_valid, steps=VALID_STEPS, verbose=2)[:config['TTA_STEPS']*ct_valid,]\n",
    "    oof_pred.append(np.mean(pred.reshape((ct_valid, config['TTA_STEPS']), order='F'), axis=1))\n",
    "    \n",
    "    # PREDICT TEST USING TTA (Loss)\n",
    "    print('Predicting Test with TTA (Loss)...')\n",
    "    pred = model.predict(ds_test, steps=TEST_STEPS, verbose=2)[:config['TTA_STEPS']*ct_test,]\n",
    "    preds[:,0] += np.mean(pred.reshape((ct_test, config['TTA_STEPS']), order='F'), axis=1) / config['N_USED_FOLDS']\n",
    "\n",
    "    # REPORT RESULTS\n",
    "    auc = roc_auc_score(oof_tar[-1], oof_pred[-1])\n",
    "    auc_last = roc_auc_score(oof_tar[-1], oof_pred_last[-1])\n",
    "    auc_blend = roc_auc_score(oof_tar[-1], np.mean([oof_pred[-1], oof_pred_last[-1]], axis=0))\n",
    "    oof_val.append(np.max(history['val_auc']))\n",
    "    print(f'#### FOLD {fold+1} OOF AUC = {oof_val[-1]:.3f}, with TTA (Loss) = {auc:.3f}, with TTA (AUC) = {auc_last:.3f}, with TTA (Blend) = {auc_blend:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Model loss graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold: 1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (12,) and (84,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-b69f257d2e32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Fold: {n_fold + 1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EPOCHS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Train AUC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#ff7f0e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'EPOCHS'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'-o'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Val AUC'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'#1f77b4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_auc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m         \"\"\"\n\u001b[1;32m   1645\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1648\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (12,) and (84,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3YAAAE1CAYAAACr/nJmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAXQklEQVR4nO3db2yV9f3/8RctgkYxrkTwMGaITLER9QYm2w1ZHKJls4jb1CaomTPWZC6auMSomwJVk61LdkOdyyLJ/LN6wzXLNFaCxHiDYfyzNSbAOiVBCDoraAlhA4V6ON8by/jJD1wPWNp+7OORmLTN59R3k3can17XdTqhVqvVAgAAQLEaRnsAAAAAvhhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAULghw66zszMLFizInDlzsmnTpiOeqVar6ejoyMKFC3PZZZelu7t72AcFAADgyIYMu0svvTRPP/10vvrVr37umeeffz7btm3LmjVr8swzz+SRRx7Je++9N6yDAgAAcGRDht1FF12USqXyP8+sWrUq11xzTRoaGtLU1JSFCxdm9erVwzYkAAAAn2/icHyT/v7+zJgx4+DnlUolH3zwQd2vP3DgQPbs2ZMTTjghEyZMGI6RAAAAilGr1TI4OJiTTz45DQ1H/1YowxJ2X9SePXs+9/k9AACA8eKcc87JlClTjvp1wxJ2lUol77//fi644IIkh1/BG8oJJ5yQ5D8/xKRJk4ZjJBg2GzduzNy5c0d7DDgi+8lYZTcZy+wnY9H+/fuzadOmg210tIYl7BYtWpTu7u5cfvnl2bVrV1566aU8/fTTdb/+v7dfTpo0KZMnTx6OkWBY2UvGMvvJWGU3GcvsJ2PVsT6aNuTNmw8++GC+9a1v5YMPPsiPfvSjXHHFFUmS9vb2bNiwIUmyZMmSzJw5M5dffnmuvfba/OQnP8nXvva1YxoIAACAozPkFbt77703995772FfX7ly5cGPGxsb09HRMbyTAQAAUJejf7sVAAAAxhRhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAUDhhBwAAULiJ9RzasmVL7r777uzatSunnXZaOjs7M2vWrEPODAwM5J577kl/f38GBwfzzW9+M/fee28mTqzrXwEAAMAxquuK3fLly7N06dK8+OKLWbp0aZYtW3bYmd/97neZPXt2nn/++Tz//PP5+9//njVr1gz7wAAAABxqyLAbGBhIX19fWltbkyStra3p6+vLzp07Dzk3YcKE7NmzJwcOHMj+/fszODiY6dOnH5+pAQAAOGjI+yT7+/szffr0NDY2JkkaGxszbdq09Pf3p6mp6eC5W2+9NbfddlsuvvjifPzxx7nuuusyb968oxpm48aNRzk+jIze3t7RHgE+l/1krLKbjGX2ky+bYXsAbvXq1ZkzZ06efPLJ7NmzJ+3t7Vm9enUWLVpU9/eYO3duJk+ePFwjwbDo7e096v9JASPFfjJW2U3GMvvJWLRv374vdKFryFsxK5VKtm/fnmq1miSpVqvZsWNHKpXKIee6urpy5ZVXpqGhIVOmTMmCBQvy+uuvH/NgAAAA1GfIsJs6dWqam5vT09OTJOnp6Ulzc/Mht2EmycyZM7N27dokyf79+/Pqq6/m7LPPPg4jAwAA8Fl1vSvmihUr0tXVlZaWlnR1daWjoyNJ0t7eng0bNiRJfvazn6W3tzeLFy/OVVddlVmzZuXaa689fpMDAACQpM5n7GbPnp3u7u7Dvr5y5cqDH5955pl5/PHHh28yAAAA6lLXFTsAAADGLmEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQOGEHAABQuLrCbsuWLWlra0tLS0va2tqydevWI55btWpVFi9enNbW1ixevDgfffTRcM4KAADAEUys59Dy5cuzdOnSLFmyJM8991yWLVuWp5566pAzGzZsyG9+85s8+eSTOf300/Ovf/0rkyZNOi5DAwAA8P8MecVuYGAgfX19aW1tTZK0tramr68vO3fuPOTcE088kZtuuimnn356kmTKlCmZPHnycRgZAACAzxryil1/f3+mT5+exsbGJEljY2OmTZuW/v7+NDU1HTy3efPmzJw5M9ddd1327t2byy67LD/+8Y8zYcKEuofZuHHjMfwIcPz19vaO9gjwuewnY5XdZCyzn3zZ1HUrZj2q1WrefvvtPP7449m/f39uvvnmzJgxI1dddVXd32Pu3Lmu8jHm9Pb2Zt68eaM9BhyR/WSsspuMZfaTsWjfvn1f6ELXkLdiViqVbN++PdVqNcl/Am7Hjh2pVCqHnJsxY0YWLVqUSZMm5ZRTTsmll16a9evXH/NgAAAA1GfIsJs6dWqam5vT09OTJOnp6Ulzc/Mht2Em/3n2bt26danVahkcHMxrr72Wc8899/hMDQAAwEF1/bmDFStWpKurKy0tLenq6kpHR0eSpL29PRs2bEiSXHHFFZk6dWq++93v5qqrrsrXv/71XH311cdvcgAAAJLU+Yzd7Nmz093dfdjXV65cefDjhoaG3HPPPbnnnnuGbzoAAACGVNcVOwAAAMYuYQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFA4YQcAAFC4usJuy5YtaWtrS0tLS9ra2rJ169bPPfvOO+/kwgsvTGdn53DNCAAAwP9QV9gtX748S5cuzYsvvpilS5dm2bJlRzxXrVazfPnyLFy4cFiHBAAA4PMNGXYDAwPp6+tLa2trkqS1tTV9fX3ZuXPnYWcfe+yxXHLJJZk1a9awDwoAAMCRDRl2/f39mT59ehobG5MkjY2NmTZtWvr7+w8599Zbb2XdunW58cYbj8ugAAAAHNnE4fgmg4ODue+++/KLX/ziYAAei40bNw7HODDsent7R3sE+Fz2k7HKbjKW2U++bIYMu0qlku3bt6daraaxsTHVajU7duxIpVI5eObDDz/Mtm3bcssttyRJdu/enVqtln//+9954IEH6h5m7ty5mTx58jH8GHD89Pb2Zt68eaM9BhyR/WSsspuMZfaTsWjfvn1f6ELXkGE3derUNDc3p6enJ0uWLElPT0+am5vT1NR08MyMGTPy+uuvH/z8kUceyd69e3PXXXcd82AAAADUp653xVyxYkW6urrS0tKSrq6udHR0JEna29uzYcOG4zogAAAA/1tdz9jNnj073d3dh3195cqVRzx/2223fbGpAAAAqFtdV+wAAAAYu4QdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4SbWc2jLli25++67s2vXrpx22mnp7OzMrFmzDjnz6KOPZtWqVWlsbMzEiRNzxx13ZP78+cdjZgAAAD6jrrBbvnx5li5dmiVLluS5557LsmXL8tRTTx1y5oILLshNN92Uk046KW+99Vauv/76rFu3LieeeOJxGRwAAID/GPJWzIGBgfT19aW1tTVJ0tramr6+vuzcufOQc/Pnz89JJ52UJJkzZ05qtVp27dp1HEYGAADgs4a8Ytff35/p06ensbExSdLY2Jhp06alv78/TU1NR3zNs88+mzPPPDNnnHHGUQ2zcePGozoPI6W3t3e0R4DPZT8Zq+wmY5n95Mumrlsxj8Ybb7yRhx56KL///e+P+rVz587N5MmTh3sk+EJ6e3szb9680R4Djsh+MlbZTcYy+8lYtG/fvi90oWvIWzErlUq2b9+earWaJKlWq9mxY0cqlcphZ998883ceeedefTRR3PWWWcd81AAAADUb8iwmzp1apqbm9PT05Mk6enpSXNz82G3Ya5fvz533HFHHn744Zx33nnHZ1oAAAAOU9ffsVuxYkW6urrS0tKSrq6udHR0JEna29uzYcOGJElHR0c++eSTLFu2LEuWLMmSJUvy9ttvH7/JAQAASFLnM3azZ89Od3f3YV9fuXLlwY//9Kc/Dd9UAAAA1K2uK3YAAACMXcIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcMIOAACgcHWF3ZYtW9LW1paWlpa0tbVl69ath52pVqvp6OjIwoULc9lll6W7u3u4ZwUAAOAI6gq75cuXZ+nSpXnxxRezdOnSLFu27LAzzz//fLZt25Y1a9bkmWeeySOPPJL33ntv2AcGAADgUBOHOjAwMJC+vr48/vjjSZLW1tY88MAD2blzZ5qamg6eW7VqVa655po0NDSkqakpCxcuzOrVq3PzzTcPOUStVkuS7N+//1h/Djiu9u3bN9ojwOeyn4xVdpOxzH4y1vy3hf7bRkdryLDr7+/P9OnT09jYmCRpbGzMtGnT0t/ff0jY9ff3Z8aMGQc/r1Qq+eCDD+oaYnBwMEmyadOmoxoeRsrGjRtHewT4XPaTscpuMpbZT8aqwcHBnHjiiUf9uiHDbiScfPLJOeecc3LCCSdkwoQJoz0OAADAiKrVahkcHMzJJ598TK8fMuwqlUq2b9+earWaxsbGVKvV7NixI5VK5bBz77//fi644IIkh1/B+18aGhoyZcqUYxgfAADgy+FYrtT915BvnjJ16tQ0Nzenp6cnSdLT05Pm5uZDbsNMkkWLFqW7uzsHDhzIzp0789JLL6WlpeWYBwMAAKA+E2p1PJ23efPm3H333dm9e3dOPfXUdHZ25qyzzkp7e3tuv/32nH/++alWq7n//vvzyiuvJEna29vT1tZ23H8AAACA8a6usAMAAGDsquvv2AEAADB2CTsAAIDCCTsAAIDCCTsAAIDCjWjYbdmyJW1tbWlpaUlbW1u2bt162JlqtZqOjo4sXLgwl112Wbq7u0dyRMaxevbz0UcfzRVXXJErr7wy3//+9/OXv/xl5Adl3KlnN//rnXfeyYUXXpjOzs6RG5Bxq97dXLVqVRYvXpzW1tYsXrw4H3300cgOyrhUz34ODAzklltuyeLFi7No0aKsWLEin3766cgPy7jS2dmZBQsWZM6cOdm0adMRzxxTE9VG0A033FB79tlna7Varfbss8/WbrjhhsPO/PnPf67ddNNNtWq1WhsYGKjNnz+/9u67747kmIxT9ezn2rVra3v37q3VarXaP/7xj9q8efNqH3/88YjOyfhTz27WarXap59+Wrv++utrP/3pT2u//OUvR3JExql6dnP9+vW173znO7UdO3bUarVabffu3bVPPvlkROdkfKpnPx988MGDvy/3799fu/rqq2svvPDCiM7J+PPXv/619v7779e+/e1v195+++0jnjmWJhqxK3YDAwPp6+tLa2trkqS1tTV9fX3ZuXPnIedWrVqVa665Jg0NDWlqasrChQuzevXqkRqTcare/Zw/f35OOumkJMmcOXNSq9Wya9euEZ+X8aPe3UySxx57LJdccklmzZo1wlMyHtW7m0888URuuummnH766UmSKVOmZPLkySM+L+NLvfs5YcKE7NmzJwcOHMj+/fszODiY6dOnj8bIjCMXXXRRKpXK/zxzLE00YmHX39+f6dOnp7GxMUnS2NiYadOmpb+//7BzM2bMOPh5pVLJBx98MFJjMk7Vu5+f9eyzz+bMM8/MGWecMVJjMg7Vu5tvvfVW1q1blxtvvHEUpmQ8qnc3N2/enHfffTfXXXddvve97+W3v/1tav6ELsdZvft56623ZsuWLbn44osP/jNv3rzRGBkOcSxN5M1T4Bi88cYbeeihh/LrX/96tEeBDA4O5r777ktHR8fB/4iBsaJarebtt9/O448/nj/84Q9Zu3ZtnnvuudEeC5Ikq1evzpw5c7Ju3bqsXbs2f/vb39wpRrFGLOwqlUq2b9+earWa5D+/6Hfs2HHYZchKpZL333//4Of9/f2uiHDc1bufSfLmm2/mzjvvzKOPPpqzzjprpEdlnKlnNz/88MNs27Ytt9xySxYsWJAnn3wyf/zjH3PfffeN1tiMA/X+3pwxY0YWLVqUSZMm5ZRTTsmll16a9evXj8bIjCP17mdXV1euvPLKNDQ0ZMqUKVmwYEFef/310RgZDnEsTTRiYTd16tQ0Nzenp6cnSdLT05Pm5uY0NTUdcm7RokXp7u7OgQMHsnPnzrz00ktpaWkZqTEZp+rdz/Xr1+eOO+7Iww8/nPPOO280RmWcqWc3Z8yYkddffz0vv/xyXn755fzwhz/MtddemwceeGC0xmYcqPf3Zmtra9atW5darZbBwcG89tprOffcc0djZMaRevdz5syZWbt2bZJk//79efXVV3P22WeP+Lzw/zuWJppQG8Eb3Tdv3py77747u3fvzqmnnprOzs6cddZZaW9vz+23357zzz8/1Wo1999/f1555ZUkSXt7e9ra2kZqRMaxevbzBz/4Qf75z38e8mD1r371q8yZM2cUJ+fLrp7d/KxHHnkke/fuzV133TVKEzNe1LObBw4cSGdnZ9auXZuGhoZcfPHFueuuu9LQ4GkQjq969nPbtm1Zvnx5Pvroo1Sr1XzjG9/Iz3/+80ycOHG0x+dL7MEHH8yaNWvy0Ucf5Stf+UpOO+20vPDCC1+4iUY07AAAABh+/ncZAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4YQdAABA4f4PbZaxk9itgvMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for n_fold, history in enumerate(history_list):\n",
    "    print(f'Fold: {n_fold + 1}')\n",
    "    plt.figure(figsize=(15,5))\n",
    "    plt.plot(np.arange(config['EPOCHS']), history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n",
    "    plt.plot(np.arange(config['EPOCHS']), history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n",
    "    x = np.argmax(history['val_auc'])\n",
    "    y = np.max(history['val_auc'])\n",
    "    xdist = plt.xlim()[1] - plt.xlim()[0]\n",
    "    ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#1f77b4')\n",
    "    plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n",
    "    plt.ylabel('AUC',size=14)\n",
    "    plt.xlabel('Epoch',size=14)\n",
    "    plt.legend(loc=2)\n",
    "    \n",
    "    plt2 = plt.gca().twinx()\n",
    "    plt2.plot(np.arange(config['EPOCHS']), history['loss'],'-o',label='Train Loss',color='#2ca02c')\n",
    "    plt2.plot(np.arange(config['EPOCHS']), history['val_loss'],'-o',label='Val Loss',color='#d62728')\n",
    "    x = np.argmin(history['val_loss'])\n",
    "    y = np.min(history['val_loss'])\n",
    "    ydist = plt.ylim()[1] - plt.ylim()[0]\n",
    "    plt.scatter(x,y,s=200,color='#d62728')\n",
    "    plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n",
    "    plt.ylabel('Loss',size=14)\n",
    "    plt.title('FOLD %i - Image Size %i' % (n_fold+1, config['HEIGHT']), size=18)\n",
    "    plt.legend(loc=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Model loss graph aggregated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "# plot_metrics_agg(history_list, config['N_USED_FOLDS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall OOF AUC with TTA (last) = 0.910\n",
      "Overall OOF AUC with TTA = 0.909\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "      <th>pred</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127506</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0076262</td>\n",
       "      <td>0</td>\n",
       "      <td>0.076390</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012835</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0082543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.022669</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  target      pred  fold\n",
       "0  ISIC_2637011       0  0.127506     0\n",
       "1  ISIC_0076262       0  0.076390     0\n",
       "2  ISIC_0074268       0  0.015113     0\n",
       "3  ISIC_0015719       0  0.012835     0\n",
       "4  ISIC_0082543       0  0.022669     0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# COMPUTE OVERALL OOF AUC (last)\n",
    "oof = np.concatenate(oof_pred_last)\n",
    "true = np.concatenate(oof_tar)\n",
    "names = np.concatenate(oof_names)\n",
    "folds = np.concatenate(oof_folds)\n",
    "auc = roc_auc_score(true, oof)\n",
    "print('Overall OOF AUC with TTA (last) = %.3f' % auc)\n",
    "\n",
    "# COMPUTE OVERALL OOF AUC\n",
    "oof = np.concatenate(oof_pred)\n",
    "true = np.concatenate(oof_tar)\n",
    "names = np.concatenate(oof_names)\n",
    "folds = np.concatenate(oof_folds)\n",
    "auc = roc_auc_score(true, oof)\n",
    "print('Overall OOF AUC with TTA = %.3f' % auc)\n",
    "\n",
    "# SAVE OOF TO DISK\n",
    "df_oof = pd.DataFrame(dict(image_name=names, target=true, pred=oof, fold=folds))\n",
    "df_oof.to_csv('oof.csv', index=False)\n",
    "df_oof.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Visualize test predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions 309|10673\n",
      "Test predictions (last) 538|10444\n",
      "Top 10 samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "      <th>target_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>0.024562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.021761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.015415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.028061</td>\n",
       "      <td>0.017294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.019559</td>\n",
       "      <td>0.031809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>ISIC_0074618</td>\n",
       "      <td>0.037453</td>\n",
       "      <td>0.081879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>ISIC_0076801</td>\n",
       "      <td>0.029927</td>\n",
       "      <td>0.061800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7203</th>\n",
       "      <td>ISIC_0077586</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>0.204212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10897</th>\n",
       "      <td>ISIC_0082004</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>0.133873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>ISIC_0082785</td>\n",
       "      <td>0.057820</td>\n",
       "      <td>0.140832</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name    target  target_last\n",
       "9905   ISIC_0052060  0.023621     0.024562\n",
       "1443   ISIC_0052349  0.023950     0.021761\n",
       "3120   ISIC_0058510  0.024104     0.015415\n",
       "4870   ISIC_0073313  0.028061     0.017294\n",
       "5494   ISIC_0073502  0.019559     0.031809\n",
       "4537   ISIC_0074618  0.037453     0.081879\n",
       "4819   ISIC_0076801  0.029927     0.061800\n",
       "7203   ISIC_0077586  0.056465     0.204212\n",
       "10897  ISIC_0082004  0.055514     0.133873\n",
       "5093   ISIC_0082785  0.057820     0.140832"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "      <th>target_last</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2280</th>\n",
       "      <td>ISIC_0112420</td>\n",
       "      <td>0.912055</td>\n",
       "      <td>0.891535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8522</th>\n",
       "      <td>ISIC_0155983</td>\n",
       "      <td>0.668529</td>\n",
       "      <td>0.761084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>ISIC_0200120</td>\n",
       "      <td>0.718880</td>\n",
       "      <td>0.828267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2519</th>\n",
       "      <td>ISIC_0208233</td>\n",
       "      <td>0.894877</td>\n",
       "      <td>0.876688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>ISIC_0216447</td>\n",
       "      <td>0.666296</td>\n",
       "      <td>0.718293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9464</th>\n",
       "      <td>ISIC_0220438</td>\n",
       "      <td>0.606465</td>\n",
       "      <td>0.777916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5072</th>\n",
       "      <td>ISIC_0259209</td>\n",
       "      <td>0.517370</td>\n",
       "      <td>0.517367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1892</th>\n",
       "      <td>ISIC_0274789</td>\n",
       "      <td>0.538437</td>\n",
       "      <td>0.624933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>ISIC_0311235</td>\n",
       "      <td>0.563850</td>\n",
       "      <td>0.750285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9372</th>\n",
       "      <td>ISIC_0367988</td>\n",
       "      <td>0.546297</td>\n",
       "      <td>0.703562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name    target  target_last\n",
       "2280  ISIC_0112420  0.912055     0.891535\n",
       "8522  ISIC_0155983  0.668529     0.761084\n",
       "1215  ISIC_0200120  0.718880     0.828267\n",
       "2519  ISIC_0208233  0.894877     0.876688\n",
       "3184  ISIC_0216447  0.666296     0.718293\n",
       "9464  ISIC_0220438  0.606465     0.777916\n",
       "5072  ISIC_0259209  0.517370     0.517367\n",
       "1892  ISIC_0274789  0.538437     0.624933\n",
       "3127  ISIC_0311235  0.563850     0.750285\n",
       "9372  ISIC_0367988  0.546297     0.703562"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = get_dataset(TEST_FILENAMES, augment=False, repeat=False, dim=config['HEIGHT'],\n",
    "                 labeled=False, return_image_names=True)\n",
    "\n",
    "image_names = np.array([img_name.numpy().decode(\"utf-8\") for img, img_name in iter(ds.unbatch())])\n",
    "\n",
    "submission = pd.DataFrame(dict(image_name=image_names, target=preds[:,0], target_last=preds_last[:,0]))\n",
    "submission = submission.sort_values('image_name')\n",
    "\n",
    "print(f\"Test predictions {len(submission[submission['target'] > .5])}|{len(submission[submission['target'] <= .5])}\")\n",
    "print(f\"Test predictions (last) {len(submission[submission['target_last'] > .5])}|{len(submission[submission['target_last'] <= .5])}\")\n",
    "\n",
    "print('Top 10 samples')\n",
    "display(submission.head(10))\n",
    "\n",
    "print('Top 10 positive samples')\n",
    "display(submission.query('target > .5').head(10))\n",
    "\n",
    "fig = plt.subplots(figsize=(20, 5))\n",
    "plt.hist(submission['target'], bins=100)\n",
    "plt.show()\n",
    "\n",
    "fig = plt.subplots(figsize=(20, 5))\n",
    "plt.hist(submission['target_last'], bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test set predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "      <th>target_last</th>\n",
       "      <th>target_blend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9905</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0.023621</td>\n",
       "      <td>0.024562</td>\n",
       "      <td>0.024091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>ISIC_0052349</td>\n",
       "      <td>0.023950</td>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.022856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3120</th>\n",
       "      <td>ISIC_0058510</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.015415</td>\n",
       "      <td>0.019760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4870</th>\n",
       "      <td>ISIC_0073313</td>\n",
       "      <td>0.028061</td>\n",
       "      <td>0.017294</td>\n",
       "      <td>0.022678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5494</th>\n",
       "      <td>ISIC_0073502</td>\n",
       "      <td>0.019559</td>\n",
       "      <td>0.031809</td>\n",
       "      <td>0.025684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4537</th>\n",
       "      <td>ISIC_0074618</td>\n",
       "      <td>0.037453</td>\n",
       "      <td>0.081879</td>\n",
       "      <td>0.059666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4819</th>\n",
       "      <td>ISIC_0076801</td>\n",
       "      <td>0.029927</td>\n",
       "      <td>0.061800</td>\n",
       "      <td>0.045863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7203</th>\n",
       "      <td>ISIC_0077586</td>\n",
       "      <td>0.056465</td>\n",
       "      <td>0.204212</td>\n",
       "      <td>0.130339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10897</th>\n",
       "      <td>ISIC_0082004</td>\n",
       "      <td>0.055514</td>\n",
       "      <td>0.133873</td>\n",
       "      <td>0.094693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5093</th>\n",
       "      <td>ISIC_0082785</td>\n",
       "      <td>0.057820</td>\n",
       "      <td>0.140832</td>\n",
       "      <td>0.099326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_name    target  target_last  target_blend\n",
       "9905   ISIC_0052060  0.023621     0.024562      0.024091\n",
       "1443   ISIC_0052349  0.023950     0.021761      0.022856\n",
       "3120   ISIC_0058510  0.024104     0.015415      0.019760\n",
       "4870   ISIC_0073313  0.028061     0.017294      0.022678\n",
       "5494   ISIC_0073502  0.019559     0.031809      0.025684\n",
       "4537   ISIC_0074618  0.037453     0.081879      0.059666\n",
       "4819   ISIC_0076801  0.029927     0.061800      0.045863\n",
       "7203   ISIC_0077586  0.056465     0.204212      0.130339\n",
       "10897  ISIC_0082004  0.055514     0.133873      0.094693\n",
       "5093   ISIC_0082785  0.057820     0.140832      0.099326"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>10982.0</td>\n",
       "      <td>0.083136</td>\n",
       "      <td>0.134647</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>0.032382</td>\n",
       "      <td>0.071363</td>\n",
       "      <td>0.981828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_last</th>\n",
       "      <td>10982.0</td>\n",
       "      <td>0.123718</td>\n",
       "      <td>0.164806</td>\n",
       "      <td>0.007893</td>\n",
       "      <td>0.022676</td>\n",
       "      <td>0.053951</td>\n",
       "      <td>0.150449</td>\n",
       "      <td>0.977302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target_blend</th>\n",
       "      <td>10982.0</td>\n",
       "      <td>0.103427</td>\n",
       "      <td>0.147257</td>\n",
       "      <td>0.009182</td>\n",
       "      <td>0.023380</td>\n",
       "      <td>0.043549</td>\n",
       "      <td>0.111784</td>\n",
       "      <td>0.978163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                count      mean       std       min       25%       50%  \\\n",
       "target        10982.0  0.083136  0.134647  0.009193  0.022972  0.032382   \n",
       "target_last   10982.0  0.123718  0.164806  0.007893  0.022676  0.053951   \n",
       "target_blend  10982.0  0.103427  0.147257  0.009182  0.023380  0.043549   \n",
       "\n",
       "                   75%       max  \n",
       "target        0.071363  0.981828  \n",
       "target_last   0.150449  0.977302  \n",
       "target_blend  0.111784  0.978163  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "submission['target_blend'] = (submission['target'] * .5) +  (submission['target_last'] * .5)\n",
    "display(submission.head(10))\n",
    "display(submission.describe().T)\n",
    "\n",
    "### BEST ###\n",
    "submission[['image_name', 'target']].to_csv('submission.csv', index=False)\n",
    "\n",
    "### LAST ###\n",
    "submission_last = submission[['image_name', 'target_last']]\n",
    "submission_last.columns = ['image_name', 'target']\n",
    "submission_last.to_csv('submission_last.csv', index=False)\n",
    "\n",
    "### BLEND ###\n",
    "submission_blend = submission[['image_name', 'target_blend']]\n",
    "submission_blend.columns = ['image_name', 'target']\n",
    "submission_blend.to_csv('submission_blend.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
